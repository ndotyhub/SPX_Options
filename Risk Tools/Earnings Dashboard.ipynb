{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning:\n",
      "\n",
      "The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Note to import from .py files, must follow structure\n",
    "# from <.py filename excluding '.py'> import <class name>\n",
    "# Optionslam creds: aspringfastlaner Options2018\n",
    "\n",
    "# Importing necessary models\n",
    "import smtplib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import pandas.stats.moments as st\n",
    "from pandas import ExcelWriter\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as dates\n",
    "import matplotlib.ticker as ticker\n",
    "from lxml import html\n",
    "import requests\n",
    "import webbrowser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import json\n",
    "import csv\n",
    "import sched, time\n",
    "import pandas_datareader as datareader\n",
    "from pandas_datareader.data import Options\n",
    "from py_vollib.black_scholes_merton.implied_volatility import *\n",
    "import dash\n",
    "from dash.dependencies import Input, Output\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output, State\n",
    "import plotly.plotly as py\n",
    "import plotly\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import skewnorm as skn\n",
    "from scipy.stats import norm\n",
    "import statsmodels.api as sm\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function for pulling implied volatility from option slam for single ticker\n",
    "'''\n",
    "\n",
    "def optionslam_scrape(ticker):\n",
    "    site = 'https://www.optionslam.com/earnings/stocks/' + ticker\n",
    "    res = requests.get(site)\n",
    "    soup = bs(requests.get(site).text, \"lxml\")\n",
    "    soup = soup.prettify()\n",
    "    earnings_dict = {'Ticker': ticker}\n",
    "    \n",
    "    # Check if there's weekly options\n",
    "    curr7_implied = \"Current 7 Day Implied Movement:\"\n",
    "    implied_move_weekly = \"Implied Move Weekly:\"\n",
    "    nextearnings = \"Next Earnings Date:\"\n",
    "    if curr7_implied not in soup:\n",
    "        return 'No Weeklies'\n",
    "    \n",
    "    # Parsing if weekly options exist\n",
    "    # Next earnings date and before or after\n",
    "    earnings_start_string = \"Next Earnings Date:\"\n",
    "    earnings_end_string = '</font>'\n",
    "    raw_earnings_string = (soup.split(earnings_start_string))[1].split(earnings_end_string)[0].replace('\\n','').strip()\n",
    "    \n",
    "    try:\n",
    "        earnings_date = str((raw_earnings_string.split('<b>'))[1].split('<font size=\"-1\">')).split(\"'\")[1].strip()\n",
    "    except:\n",
    "        return 'Error Parsing'\n",
    "    \n",
    "    earnings_time = str(raw_earnings_string[-2:].strip()).strip()\n",
    "    \n",
    "    earnings_dict['Date'] = earnings_date\n",
    "    earnings_dict['Earnings Time'] = earnings_time\n",
    "    \n",
    "    # Parsing 7 day implied move if weekly option exists\n",
    "    ending_string = '<font size=\"-2\">'\n",
    "    curr_7 = (soup.split(curr7_implied))[1].split(ending_string)[0].replace('\\n','').strip(\"\").split(\"<td>\")[-1].strip()\n",
    "    earnings_dict['Current 7 Day Implied'] = curr_7\n",
    "    \n",
    "    # Parsing Weekly Implied move if weekly option exists\n",
    "    if implied_move_weekly in soup:\n",
    "        weekly_implied = (soup.split(implied_move_weekly))[1].split(ending_string)[0].replace('\\n','').strip(\"\").split(\"<td>\")[-1].strip()\n",
    "    else:\n",
    "        weekly_implied = ''\n",
    "    earnings_dict[\"Implied Move Weekly\"] = weekly_implied\n",
    "    \n",
    "    return earnings_dict\n",
    "\n",
    "\n",
    "def generate_table(dataframe):\n",
    "    return html.Table(\n",
    "        # Header\n",
    "        [html.Tr([html.Th(col) for col in dataframe.columns])] +\n",
    "\n",
    "        # Body\n",
    "        [html.Tr([\n",
    "            html.Td(dataframe.iloc[i][col]) for col in dataframe.columns\n",
    "        ]) for i in range(len(dataframe))]\n",
    "    )\n",
    "\n",
    "\n",
    "# Looping through the soup lxml text table format\n",
    "# and splitting each row as a individual string\n",
    "# and parsing string to retrieve the date,\n",
    "# open, and close information.\n",
    "\n",
    "def yahoo_table_parse(raw_html_table):\n",
    "    tickers = []\n",
    "    call_times = []\n",
    "    implied_7_day = []\n",
    "    implied_weekly = []\n",
    "    eps = []\n",
    "    i = 1\n",
    "    end_row = 10\n",
    "    for row in raw_html_table.find_all('tr'):\n",
    "        # Individual row stores current row item and delimits on '\\n'\n",
    "        individual_row = str(row).split('\\n')\n",
    "        row_items = individual_row[0].split('</span>')[:3]\n",
    "\n",
    "        if i == 1:\n",
    "            i += 1\n",
    "            continue\n",
    "        tick = row_items[0].split('data-symbol=\"')[1].split('\"')[0]\n",
    "        os_check = optionslam_scrape(tick)\n",
    "\n",
    "        if type(os_check) == str:\n",
    "            continue\n",
    "        else:\n",
    "            tickers.append(tick)\n",
    "            call_times.append(row_items[0].split('data-symbol=\"')[1].split('\"')[-1].replace('>',''))\n",
    "            eps.append(row_items[1].split('</td>')[1].split('>')[1])\n",
    "            implied_7_day.append(os_check['Current 7 Day Implied'].replace('%',''))\n",
    "            implied_weekly.append(os_check['Implied Move Weekly'].replace('%',''))\n",
    "\n",
    "\n",
    "    return pd.DataFrame({'Tickers': tickers, 'Call Times': call_times, 'EPS': eps,\n",
    "                         'Current 7 Day Implied': implied_7_day,\n",
    "                         'Implied Move Weekly': implied_weekly})\n",
    "\n",
    "\n",
    "def yahoo_earnings(date):\n",
    "    # Yahoo Earnings Calendar Check\n",
    "\n",
    "    today = date.strftime('%Y-%m-%d')\n",
    "    tables = []\n",
    "    for i in range(6):\n",
    "        yahoo_url = 'https://finance.yahoo.com/calendar/earnings?day=' + today + '&offset={}&size=100'.format(int(i*100))\n",
    "        res = requests.get(yahoo_url)\n",
    "        soup = bs(requests.get(yahoo_url).text, \"lxml\")\n",
    "\n",
    "        try:\n",
    "            table = soup.find_all('table')[0]\n",
    "            tables.append(yahoo_table_parse(table))\n",
    "        except:\n",
    "            print('No Table')\n",
    "\n",
    "    return pd.concat(tables,axis = 0, ignore_index = True)\n",
    "\n",
    "\n",
    "def close_data(ticker_lst, start_date = dt.datetime(2018, 2, 20)):\n",
    "    # Define which online source one should use\n",
    "    data_source = 'yahoo'\n",
    "\n",
    "    end = dt.datetime.today()\n",
    "\n",
    "    # User pandas_reader.data.DataReader to load the desired data. As simple as that.\n",
    "    panel_data = datareader.DataReader(ticker_lst, data_source, start_date, end)\n",
    "\n",
    "    # Getting just the adjusted closing prices. This will return a Pandas DataFrame\n",
    "    # The index in this DataFrame is the major index of the panel_data.\n",
    "    return panel_data.ix['Close']\n",
    "\n",
    "'''\n",
    "Function for pulling latest SPX, VIX, VVIX, or SKEW data. Input is a string, pulls \n",
    "the latest 2 lines of data from yahoo finance for given ticker and returns a \n",
    "dataframe of the open and close with the latest date as the first row.\n",
    "'''\n",
    "def latest_yahoo(ticker):\n",
    "    # Using requests to ping yahoo finance to retrieve \n",
    "    # historical data table\n",
    "    site = 'https://finance.yahoo.com/quote/{0}/history?p={0}'.format(ticker)\n",
    "    \n",
    "    res = requests.get(site)\n",
    "    soup = bs(res.text, 'lxml')\n",
    "    table = soup.find_all('table')[0]\n",
    "\n",
    "    # Looping through the soup lxml text table format\n",
    "    # and splitting each row as a individual string\n",
    "    # and parsing string to retrieve the date,\n",
    "    # open, and close information.\n",
    "    i = 1\n",
    "    end_row = 3\n",
    "    for row in table.find_all('tr'):\n",
    "        # Individual row stores current row item and delimits on '\\n'\n",
    "        individual_row = str(row).split('\\n')\n",
    "        \n",
    "        # row_items is parsed string for each current row where each\n",
    "        # item in list is the date, open, high, low, close, and volume\n",
    "        row_items = [item.split('>')[1] for item in [string.split('</span>')[0] for string in individual_row[0].split('<span ')[1:]]]\n",
    "        \n",
    "        if i == 1:\n",
    "            # Skip first row because they are column headers\n",
    "            i += 1\n",
    "            continue\n",
    "        elif i == end_row:\n",
    "            break\n",
    "        else:\n",
    "            # Append necessary items to initialized lists for \n",
    "            # dataframe storage\n",
    "            close = float(row_items[5].replace(',',''))\n",
    "        i += 1\n",
    "    \n",
    "    # Return dataframe of necessary values\n",
    "    return np.round(np.float(close),2)\n",
    "\n",
    "# Function for calculating standard dev and price moves in terms of standard dev\n",
    "# DF[[Adj Close]] Rolling Period --> DF[['Daily Vol','Daily Price Vol','Price Dev','Annual Vol']]\n",
    "def price_devs(ticker, lookbackwindow, rollingperiod):\n",
    "    # Define which online source one should use\n",
    "    data_source = 'yahoo'\n",
    "    \n",
    "    end = dt.datetime.today()\n",
    "    start_date = end - dt.timedelta(days = lookbackwindow)\n",
    "    \n",
    "    # User pandas_reader.data.DataReader to load the desired data. As simple as that.\n",
    "    df = datareader.DataReader([ticker], data_source, start_date, end).sort_index()\n",
    "\n",
    "    # Getting just the adjusted closing prices. This will return a Pandas DataFrame\n",
    "    # The index in this DataFrame is the major index of the panel_data.\n",
    "    df = df.ix['Close'].sort_index()\n",
    "    \n",
    "    df.columns = ['prices']\n",
    "    df['prices_delta'] = df.prices - df.prices.shift(1)\n",
    "    df['log_returns'] = np.log(df.prices) - np.log(df.prices.shift(1))\n",
    "    df['daily_vol'] = st.rolling_std(df.log_returns, rollingperiod, ddof = 1)\n",
    "    df['daily_vol_dollar'] = df.daily_vol*df.prices\n",
    "    df['price_dev'] = df.prices_delta/df.daily_vol_dollar.shift(1)\n",
    "    df['annual_vol'] = df.daily_vol*np.sqrt(252)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:8050/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [20/Jun/2018 15:22:40] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Jun/2018 15:22:42] \"GET /_dash-layout HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Jun/2018 15:22:42] \"GET /_dash-dependencies HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Jun/2018 15:22:42] \"GET /favicon.ico HTTP/1.1\" 200 -\n",
      "[2018-06-20 15:22:42,463] ERROR in app: Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1982, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1614, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1517, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\flask\\_compat.py\", line 33, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1612, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1598, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\dash\\dash.py\", line 551, in dispatch\n",
      "    return self.callback_map[target_id]['callback'](*args)\n",
      "  File \"C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\dash\\dash.py\", line 508, in add_context\n",
      "    output_value = func(*args, **kwargs)\n",
      "  File \"<ipython-input-3-9c60223b4de0>\", line 312, in update_large_spike\n",
      "    '''.format(np.round(retdata.iloc[retdata.index.get_loc(retdata.idxmax())], 2),\n",
      "NameError: name 'retdata' is not defined\n",
      "127.0.0.1 - - [20/Jun/2018 15:22:42] \"POST /_dash-update-component HTTP/1.1\" 500 -\n",
      "[2018-06-20 15:22:42,472] ERROR in app: Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1982, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1614, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1517, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\flask\\_compat.py\", line 33, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1612, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1598, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\dash\\dash.py\", line 551, in dispatch\n",
      "    return self.callback_map[target_id]['callback'](*args)\n",
      "  File \"C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\dash\\dash.py\", line 508, in add_context\n",
      "    output_value = func(*args, **kwargs)\n",
      "  File \"<ipython-input-3-9c60223b4de0>\", line 297, in update_large_drop\n",
      "    '''.format(np.round(retdata.iloc[retdata.index.get_loc(retdata.idxmin())], 2),\n",
      "NameError: name 'retdata' is not defined\n",
      "127.0.0.1 - - [20/Jun/2018 15:22:42] \"POST /_dash-update-component HTTP/1.1\" 500 -\n",
      "[2018-06-20 15:22:42,477] ERROR in app: Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1982, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1614, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1517, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\flask\\_compat.py\", line 33, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1612, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1598, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\dash\\dash.py\", line 551, in dispatch\n",
      "    return self.callback_map[target_id]['callback'](*args)\n",
      "  File \"C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\dash\\dash.py\", line 508, in add_context\n",
      "    output_value = func(*args, **kwargs)\n",
      "  File \"<ipython-input-3-9c60223b4de0>\", line 259, in update_bar\n",
      "    x=retdata.index,\n",
      "NameError: name 'retdata' is not defined\n",
      "127.0.0.1 - - [20/Jun/2018 15:22:42] \"POST /_dash-update-component HTTP/1.1\" 500 -\n",
      "[2018-06-20 15:23:25,628] ERROR in app: Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1982, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1614, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1517, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\flask\\_compat.py\", line 33, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1612, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1598, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\dash\\dash.py\", line 551, in dispatch\n",
      "    return self.callback_map[target_id]['callback'](*args)\n",
      "  File \"C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\dash\\dash.py\", line 508, in add_context\n",
      "    output_value = func(*args, **kwargs)\n",
      "  File \"<ipython-input-3-9c60223b4de0>\", line 222, in update_histogram\n",
      "    retdata = price_devs(ticker, lookbackwindow, rollingperiod)[histfield].dropna()\n",
      "  File \"<ipython-input-2-85bd71d9b550>\", line 186, in price_devs\n",
      "    df = datareader.DataReader([ticker], data_source, start_date, end).sort_index()\n",
      "  File \"C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\pandas_datareader\\data.py\", line 121, in DataReader\n",
      "    session=session).read()\n",
      "  File \"C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\pandas_datareader\\yahoo\\daily.py\", line 82, in __init__\n",
      "    self.crumb = self._get_crumb(retry_count)\n",
      "  File \"C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\pandas_datareader\\yahoo\\daily.py\", line 163, in _get_crumb\n",
      "    crumb = re.findall(rpat, out)[0]\n",
      "IndexError: list index out of range\n",
      "127.0.0.1 - - [20/Jun/2018 15:23:25] \"POST /_dash-update-component HTTP/1.1\" 500 -\n",
      "[2018-06-20 15:23:25,643] ERROR in app: Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1982, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1614, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1517, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\flask\\_compat.py\", line 33, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1612, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1598, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\dash\\dash.py\", line 551, in dispatch\n",
      "    return self.callback_map[target_id]['callback'](*args)\n",
      "  File \"C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\dash\\dash.py\", line 508, in add_context\n",
      "    output_value = func(*args, **kwargs)\n",
      "  File \"<ipython-input-3-9c60223b4de0>\", line 203, in earnings_table_data\n",
      "    output_table = earnings_table.copy()\n",
      "NameError: name 'earnings_table' is not defined\n",
      "127.0.0.1 - - [20/Jun/2018 15:23:25] \"POST /_dash-update-component HTTP/1.1\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Table\n",
      "No Table\n",
      "No Table\n",
      "No Table\n"
     ]
    }
   ],
   "source": [
    "# Setup app\n",
    "# server = flask.Flask(__name__)\n",
    "# server.secret_key = os.environ.get('secret_key', 'secret')\n",
    "# app = dash.Dash(__name__, server=server, url_base_pathname='/dash/gallery/volatility-surface', csrf_protect=False)\n",
    "app = dash.Dash()\n",
    "\n",
    "external_css = [\"https://fonts.googleapis.com/css?family=Overpass:300,300i\",\n",
    "                \"https://cdn.rawgit.com/plotly/dash-app-stylesheets/dab6f937fd5548cebf4c6dc7e93a10ac438f5efb/dash-technical-charting.css\"]\n",
    "\n",
    "for css in external_css:\n",
    "    app.css.append_css({\"external_url\": css})\n",
    "\n",
    "if 'DYNO' in os.environ:\n",
    "    app.scripts.append_script({\n",
    "        'external_url': 'https://cdn.rawgit.com/chriddyp/ca0d8f02a1659981a0ea7f013a378bbd/raw/e79f3f789517deec58f41251f7dbb6bee72c44ab/plotly_ga.js'\n",
    "    })\n",
    "\n",
    "\n",
    "# Plot Fields\n",
    "returncolumns = ['price_dev','log_returns']\n",
    "plotfields = [dict(label=str(x), value=str(x)) for x in returncolumns]\n",
    "\n",
    "# Current data table for graphing\n",
    "# curr_data = np.round(datacollect.curr_table.tail(),2)\n",
    "# curr_data['Date'] = datacollect.curr_table.tail().index\n",
    "# curr_data = curr_data.iloc[:,::-1]\n",
    "\n",
    "#curr_data = yahoo_earnings()\n",
    "\n",
    "# Make app layout\n",
    "app.layout = html.Div(\n",
    "    [# Titles\n",
    "        html.Div([\n",
    "            html.Img(\n",
    "                src=\"http://fchen.info/wp-content/uploads/2016/10/fclogo2.png\",\n",
    "                className='five columns',\n",
    "                style={\n",
    "                    'height': '60',\n",
    "                    'width': '60',\n",
    "                    'float': 'left',\n",
    "                    'text-align': 'center'\n",
    "                },\n",
    "            ),\n",
    "            html.H1(\n",
    "                'Earnings Checking Tool',\n",
    "                className='seven columns',\n",
    "                style={'text-align': 'center'}\n",
    "            ),\n",
    "        ],\n",
    "            className='row'\n",
    "        ),\n",
    "        # First Row\n",
    "        html.Hr(style={'margin': '0', 'margin-bottom': '5'}),\n",
    "        html.Div([\n",
    "            html.Div([\n",
    "                html.Label('Historical Data Checking:'),\n",
    "                html.Div([\n",
    "                    html.Label('Lookback Window:'),\n",
    "                    dcc.Slider(\n",
    "                        id='lookback-slider',\n",
    "                        min = 100,\n",
    "                        max = 10000,\n",
    "                        value = 500,\n",
    "                    ),\n",
    "                ],\n",
    "                className = 'row',\n",
    "                style={'padding': '3%'}),\n",
    "                html.Div([\n",
    "                    html.Label('Days for Volatility Calculation:'),\n",
    "                    dcc.Slider(\n",
    "                        marks={i: '{}'.format(i) for i in range(5,30)},\n",
    "                        id='voldays-slider',\n",
    "                        min = 5,\n",
    "                        max = 30,\n",
    "                        value = 20,\n",
    "                    )\n",
    "                ],\n",
    "                className = 'row',\n",
    "                style={'padding': '3%'}),\n",
    "                \n",
    "                html.Div([\n",
    "                    html.Label('Ticker Lookup'),\n",
    "                    dcc.Input(id='ticker-input', type='text', value='AAPL')\n",
    "                ],\n",
    "                className = 'row',\n",
    "                style={'padding': '3%'}),\n",
    "                \n",
    "                html.Div([\n",
    "                    html.Label('Histogram Field'),\n",
    "                    dcc.Dropdown(\n",
    "                            id='hist-dropdown',\n",
    "                            options=plotfields,\n",
    "                            value='price_dev',\n",
    "                    )\n",
    "                ],\n",
    "                className = 'row',\n",
    "                style={'padding': '3%'}),\n",
    "                \n",
    "                html.Button(id='submit-ticker', n_clicks=0, children='Ticker Lookup')\n",
    "            ],\n",
    "                className='eight columns',\n",
    "            ),\n",
    "            html.Div([\n",
    "                \n",
    "                html.Div([\n",
    "                    html.Label('Earnings Date:'),\n",
    "                    dcc.DatePickerSingle(\n",
    "                        id='earnings-date',\n",
    "                        date=dt.datetime.now().date()\n",
    "                    ),\n",
    "                    html.Button(id='submit-yahoo', n_clicks=0, children='Update Date')\n",
    "                ],\n",
    "                className = 'row',\n",
    "                style={'padding': '3%'}),\n",
    "                                \n",
    "                html.Div([\n",
    "                    html.Label('Call Time Filter:'),\n",
    "                    dcc.RadioItems(\n",
    "                        id='open_close_selector',\n",
    "                        options=[\n",
    "                            {'label': 'Before Market Open', 'value': 'Before Market Open'},\n",
    "                            {'label': 'After Market Close', 'value': 'After Market Close'},\n",
    "                        ],\n",
    "                        value = 'Before Market Open',\n",
    "                        labelStyle={'display': 'inline-block'},\n",
    "                    ),\n",
    "                    html.Button(id='submit-filter', n_clicks=0, children='Call Time Update')\n",
    "                ],\n",
    "                className = 'row',\n",
    "                style={'padding': '3%'})\n",
    "            ],\n",
    "                className='four columns',\n",
    "            )\n",
    "        ],\n",
    "            className='row',\n",
    "            style={'margin-bottom': '1%'}\n",
    "        ),\n",
    "        \n",
    "                \n",
    "        ## Second Row\n",
    "        html.Div([\n",
    "            html.Div([\n",
    "                html.Div([\n",
    "                    dcc.Graph(id = 'return-distribution', style={'max-height': '450', 'height': '60vh'})\n",
    "                ],\n",
    "                    className = 'row'),\n",
    "                html.Div([\n",
    "                    dcc.Graph(id = 'return-history', style={'max-height': '450', 'height': '60vh'})\n",
    "                ],\n",
    "                    className = 'row'),\n",
    "                html.Div(id = 'largest-drop', className = 'row'),\n",
    "                html.Div(id = 'largest-spike', className = 'row')\n",
    "            ],\n",
    "                className='eight columns'\n",
    "            ),\n",
    "            html.Div(id = 'worst-table', className = 'four columns')\n",
    "        ],\n",
    "            className='row',\n",
    "            style={'margin-bottom': '2%'}\n",
    "        ),\n",
    "        \n",
    "        \n",
    "        # Temporary hack for live dataframe caching\n",
    "        # 'hidden' set to 'loaded' triggers next callback\n",
    "        html.P(\n",
    "            hidden='',\n",
    "            id='earnings-data',\n",
    "            style={'display': 'none'}\n",
    "        )\n",
    "    ],\n",
    "    style={\n",
    "        'width': '85%',\n",
    "        'max-width': '1200',\n",
    "        'margin-left': 'auto',\n",
    "        'margin-right': 'auto',\n",
    "        'font-family': 'overpass',\n",
    "        'background-color': '#FFFFFF',\n",
    "        'padding': '40',\n",
    "        'padding-top': '20',\n",
    "        'padding-bottom': '20',\n",
    "    },\n",
    ")\n",
    "\n",
    "# Cache raw data\n",
    "# Callback function to load worst return recalculated data\n",
    "# into global worst_return_data for useage\n",
    "@app.callback(Output('earnings-data', 'hidden'),\n",
    "              [Input('submit-yahoo', 'n_clicks')],\n",
    "              [State('earnings-date', 'date')])\n",
    "def cache_raw_data(n_clicks, datepick):\n",
    "    date_string = dt.datetime.strptime(datepick, '%Y-%m-%d')    \n",
    "    global earnings_table\n",
    "    earnings_table = yahoo_earnings(date_string)\n",
    "    \n",
    "    print('Loaded raw data')\n",
    "\n",
    "    return 'Earnings loaded'\n",
    "\n",
    "@app.callback(Output('worst-table', 'children'),\n",
    "              [Input('submit-filter', 'n_clicks')],\n",
    "              [State('open_close_selector', 'value')])\n",
    "def earnings_table_data(n_clicks, calltime):\n",
    "    output_table = earnings_table.copy()\n",
    "    output_table['Close'] = np.nan\n",
    "    for idx, row in earnings_table.iterrows():\n",
    "        output_table['Close'].loc[idx] = latest_yahoo(row['Tickers'])\n",
    "        time.sleep(1)\n",
    "    output_table['Implied Down Price'] = np.round((1 - output_table['Current 7 Day Implied'].apply(pd.to_numeric)/100)*output_table['Close'],2)\n",
    "    \n",
    "    return generate_table(output_table[output_table['Call Times'] == calltime])\n",
    "\n",
    "# Callback function for yahoo latest options data\n",
    "@app.callback(Output('return-distribution', 'figure'),\n",
    "              [Input('submit-ticker', 'n_clicks')],\n",
    "              [State('ticker-input', 'value'),\n",
    "               State('lookback-slider', 'value'),\n",
    "               State('voldays-slider', 'value'),\n",
    "               State('hist-dropdown', 'value')])\n",
    "def update_histogram(n_clicks, ticker, lookbackwindow, rollingperiod, histfield):\n",
    "    \n",
    "    global retdata\n",
    "    retdata = price_devs(ticker, lookbackwindow, rollingperiod)[histfield].dropna()\n",
    "\n",
    "    trace1 = go.Histogram(\n",
    "        x=retdata,\n",
    "        histnorm='count',\n",
    "        name='control',\n",
    "#         xbins=dict(\n",
    "#             start=-2.0,\n",
    "#             end=2.0,\n",
    "#             size=0.001\n",
    "#         ),\n",
    "        opacity=0.75\n",
    "    )\n",
    "\n",
    "    data = [trace1]\n",
    "\n",
    "    layout = go.Layout(\n",
    "        title= ticker + ' Return Distribution',\n",
    "        xaxis=dict(\n",
    "            title=histfield\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title='Count'\n",
    "        ),\n",
    "        bargap=0.2,\n",
    "        bargroupgap=0.1\n",
    "    )\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    return fig\n",
    "\n",
    "# Callback function for yahoo latest options data\n",
    "@app.callback(Output('return-history', 'figure'),\n",
    "              [Input('submit-ticker', 'n_clicks')],\n",
    "              [State('ticker-input', 'value')])\n",
    "def update_bar(n_clicks, ticker):\n",
    "    \n",
    "    trace1 = go.Bar(\n",
    "        x=retdata.index,\n",
    "        y=retdata.values,\n",
    "        name=retdata.name\n",
    "    )\n",
    "\n",
    "    data = [trace1]\n",
    "    layout = go.Layout(\n",
    "        title=ticker + ' Historical Profile',\n",
    "        xaxis=dict(\n",
    "            title = 'Date',\n",
    "            tickfont=dict(\n",
    "                size=14\n",
    "            )\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title=retdata.name,\n",
    "            titlefont=dict(\n",
    "                size=16\n",
    "            ),\n",
    "            tickfont=dict(\n",
    "                size=14\n",
    "            )\n",
    "        ),\n",
    "        bargap=0.15\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    return fig\n",
    "\n",
    "# Callback function for yahoo latest options data\n",
    "@app.callback(Output('largest-drop', 'children'),\n",
    "              [Input('submit-ticker', 'n_clicks')],\n",
    "              [State('ticker-input', 'value')])\n",
    "def update_large_drop(n_clicks, ticker):\n",
    "    \n",
    "    # Finding date of largest drop\n",
    "    dropstring = '''\n",
    "    Largest drop for {2} was {0} and occured on {1}\n",
    "    '''.format(np.round(retdata.iloc[retdata.index.get_loc(retdata.idxmin())], 2),\n",
    "               retdata.idxmin().strftime('%Y-%m-%d'),\n",
    "               ticker)   \n",
    "    \n",
    "    return dropstring\n",
    "\n",
    "# Callback function for yahoo latest options data\n",
    "@app.callback(Output('largest-spike', 'children'),\n",
    "              [Input('submit-ticker', 'n_clicks')],\n",
    "              [State('ticker-input', 'value')])\n",
    "def update_large_spike(n_clicks, ticker):\n",
    "    \n",
    "    # Finding date of largest drop\n",
    "    spikestring = '''\n",
    "    Largest Spike for {2} was {0} and occured on {1}\n",
    "    '''.format(np.round(retdata.iloc[retdata.index.get_loc(retdata.idxmax())], 2),\n",
    "               retdata.idxmax().strftime('%Y-%m-%d'),\n",
    "               ticker)\n",
    "    \n",
    "    return spikestring\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
