{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note to import from .py files, must follow structure\n",
    "# from <.py filename excluding '.py'> import <class name>\n",
    "# Optionslam creds: aspringfastlaner Options2018\n",
    "\n",
    "# Importing necessary models\n",
    "import smtplib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import pandas.stats.moments as st\n",
    "from pandas import ExcelWriter\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as dates\n",
    "# import matplotlib.ticker as ticker\n",
    "from lxml import html\n",
    "import requests\n",
    "import webbrowser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import json\n",
    "import csv\n",
    "import sched, time\n",
    "import pandas_datareader as datareader\n",
    "from pandas_datareader.data import Options\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Alpha Vantage API Key\n",
    "# 5HZEUI5AFJB06BUK\n",
    "\n",
    "# ts = TimeSeries(key='5HZEUI5AFJB06BUK', output_format='pandas')\n",
    "# data, meta_data = ts.get_intraday(symbol='MSFT',interval='1min', outputsize='full')\n",
    "# data['close'].plot()\n",
    "# plt.title('Intraday Times Series for the MSFT stock (1 min)')\n",
    "# For intraday\n",
    "# https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY&symbol=MSFT&interval=1min&apikey=d5HZEUI5AFJB06BUK&datatype=csv\n",
    "\n",
    "# For daily\n",
    "# https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol=MSFT&apikey=5HZEUI5AFJB06BUK&datatype=csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Pulling S&P 500 Names\n",
    "'''\n",
    "\n",
    "def pull_sp500_list():\n",
    "    site = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "    res = requests.get(site)\n",
    "    soup = bs(res.text, 'lxml')\n",
    "    table = soup.find_all('table')[0]\n",
    "\n",
    "    tickers = []\n",
    "    names = []\n",
    "    gics = []\n",
    "\n",
    "    # Looping through the soup lxml text table format\n",
    "    # and splitting each row as a individual string\n",
    "    # and parsing string to retrieve the date,\n",
    "    # open, and close information.\n",
    "    i = 1\n",
    "    for row in table.find_all('tr'):\n",
    "        if i == 1:\n",
    "            i += 1\n",
    "            continue\n",
    "        # Individual row stores current row item and delimits on '\\n'\n",
    "        individual_row = str(row).split('\\n')\n",
    "        # row_items is parsed string for each current row where each\n",
    "        ticker = individual_row[1].split('\">')[-1].split('<')[0]\n",
    "        tickers.append(ticker)\n",
    "        name = individual_row[2].split('\">')[-1].split('<')[0]\n",
    "        names.append(name)\n",
    "        gic = individual_row[4].split('>')[1].split('<')[0]\n",
    "        gics.append(gic)\n",
    "\n",
    "    sp500 = pd.DataFrame({'Name': names, 'GIC': gics}, index = tickers)\n",
    "    return sp500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function for pulling implied volatility from option slam for single ticker\n",
    "'''\n",
    "\n",
    "def optionslam_scrape(ticker):\n",
    "    site = 'https://www.optionslam.com/earnings/stocks/' + ticker\n",
    "    res = requests.get(site)\n",
    "    soup = bs(requests.get(site).text, \"lxml\")\n",
    "    soup = soup.prettify()\n",
    "    earnings_dict = {'Ticker': ticker}\n",
    "    \n",
    "    # Check if there's weekly options\n",
    "    curr7_implied = \"Current 7 Day Implied Movement:\"\n",
    "    implied_move_weekly = \"Implied Move Weekly:\"\n",
    "    nextearnings = \"Next Earnings Date:\"\n",
    "    if curr7_implied not in soup:\n",
    "        return 'No Weeklies'\n",
    "    \n",
    "    # Parsing if weekly options exist\n",
    "    # Next earnings date and before or after\n",
    "    earnings_start_string = \"Next Earnings Date:\"\n",
    "    earnings_end_string = '</font>'\n",
    "    raw_earnings_string = (soup.split(earnings_start_string))[1].split(earnings_end_string)[0].replace('\\n','').strip()\n",
    "    \n",
    "    try:\n",
    "        earnings_date = str((raw_earnings_string.split('<b>'))[1].split('<font size=\"-1\">')).split(\"'\")[1].strip()\n",
    "    except:\n",
    "        return 'Error Parsing'\n",
    "    \n",
    "    earnings_time = str(raw_earnings_string[-2:].strip()).strip()\n",
    "    \n",
    "    earnings_dict['Date'] = earnings_date\n",
    "    earnings_dict['Earnings Time'] = earnings_time\n",
    "    \n",
    "    # Parsing 7 day implied move if weekly option exists\n",
    "    ending_string = '<font size=\"-2\">'\n",
    "    curr_7 = (soup.split(curr7_implied))[1].split(ending_string)[0].replace('\\n','').strip(\"\").split(\"<td>\")[-1].strip()\n",
    "    earnings_dict['Current 7 Day Implied'] = curr_7\n",
    "    \n",
    "    # Parsing Weekly Implied move if weekly option exists\n",
    "    if implied_move_weekly in soup:\n",
    "        weekly_implied = (soup.split(implied_move_weekly))[1].split(ending_string)[0].replace('\\n','').strip(\"\").split(\"<td>\")[-1].strip()\n",
    "    else:\n",
    "        weekly_implied = ''\n",
    "    earnings_dict[\"Implied Move Weekly\"] = weekly_implied\n",
    "    \n",
    "    return earnings_dict\n",
    "\n",
    "# Looping through the soup lxml text table format\n",
    "# and splitting each row as a individual string\n",
    "# and parsing string to retrieve the date,\n",
    "# open, and close information.\n",
    "\n",
    "def yahoo_table_parse(raw_html_table):\n",
    "    tickers = []\n",
    "    call_times = []\n",
    "    implied_7_day = []\n",
    "    implied_weekly = []\n",
    "    eps = []\n",
    "    i = 1\n",
    "    end_row = 10\n",
    "    for row in raw_html_table.find_all('tr'):\n",
    "        # Individual row stores current row item and delimits on '\\n'\n",
    "        individual_row = str(row).split('\\n')\n",
    "        row_items = individual_row[0].split('</span>')[:3]\n",
    "\n",
    "        if i == 1:\n",
    "            i += 1\n",
    "            continue\n",
    "        tick = row_items[0].split('data-symbol=\"')[1].split('\"')[0]\n",
    "        os_check = optionslam_scrape(tick)\n",
    "\n",
    "        if type(os_check) == str:\n",
    "            continue\n",
    "        else:\n",
    "            tickers.append(tick)\n",
    "            call_times.append(row_items[0].split('data-symbol=\"')[1].split('\"')[-1].replace('>',''))\n",
    "            eps.append(row_items[1].split('</td>')[1].split('>')[1])\n",
    "            implied_7_day.append(os_check['Current 7 Day Implied'].replace('%',''))\n",
    "            implied_weekly.append(os_check['Implied Move Weekly'].replace('%',''))\n",
    "\n",
    "\n",
    "    return pd.DataFrame({'Tickers': tickers, 'Call Times': call_times, 'EPS': eps,\n",
    "                         'Current 7 Day Implied': implied_7_day,\n",
    "                         'Implied Move Weekly': implied_weekly})\n",
    "\n",
    "\n",
    "def yahoo_earnings(date):\n",
    "    # Yahoo Earnings Calendar Check\n",
    "\n",
    "    today = date.strftime('%Y-%m-%d')\n",
    "    tables = []\n",
    "    for i in range(6):\n",
    "        yahoo_url = 'https://finance.yahoo.com/calendar/earnings?day=' + today + '&offset={}&size=100'.format(int(i*100))\n",
    "        res = requests.get(yahoo_url)\n",
    "        soup = bs(requests.get(yahoo_url).text, \"lxml\")\n",
    "\n",
    "        try:\n",
    "            table = soup.find_all('table')[0]\n",
    "            tables.append(yahoo_table_parse(table))\n",
    "        except:\n",
    "            print('No Table')\n",
    "\n",
    "    return pd.concat(tables,axis = 0, ignore_index = True)\n",
    "\n",
    "\n",
    "def close_data(ticker_lst, start_date = dt.datetime(2018, 2, 20)):\n",
    "    # Define which online source one should use\n",
    "    data_source = 'yahoo'\n",
    "\n",
    "    end = dt.datetime.today()\n",
    "\n",
    "    # User pandas_reader.data.DataReader to load the desired data. As simple as that.\n",
    "    panel_data = datareader.DataReader(ticker_lst, data_source, start_date, end)\n",
    "\n",
    "    # Getting just the adjusted closing prices. This will return a Pandas DataFrame\n",
    "    # The index in this DataFrame is the major index of the panel_data.\n",
    "    return panel_data.ix['Close']\n",
    "\n",
    "'''\n",
    "Function for pulling latest SPX, VIX, VVIX, or SKEW data. Input is a string, pulls \n",
    "the latest 2 lines of data from yahoo finance for given ticker and returns a \n",
    "dataframe of the open and close with the latest date as the first row.\n",
    "'''\n",
    "def latest_yahoo(ticker):\n",
    "    # Using requests to ping yahoo finance to retrieve \n",
    "    # historical data table\n",
    "    site = 'https://finance.yahoo.com/quote/{0}/history?p={0}'.format(ticker)\n",
    "    \n",
    "    res = requests.get(site)\n",
    "    soup = bs(res.text, 'lxml')\n",
    "    table = soup.find_all('table')[0]\n",
    "\n",
    "    # Looping through the soup lxml text table format\n",
    "    # and splitting each row as a individual string\n",
    "    # and parsing string to retrieve the date,\n",
    "    # open, and close information.\n",
    "    i = 1\n",
    "    end_row = 3\n",
    "    for row in table.find_all('tr'):\n",
    "        # Individual row stores current row item and delimits on '\\n'\n",
    "        individual_row = str(row).split('\\n')\n",
    "        \n",
    "        # row_items is parsed string for each current row where each\n",
    "        # item in list is the date, open, high, low, close, and volume\n",
    "        row_items = [item.split('>')[1] for item in [string.split('</span>')[0] for string in individual_row[0].split('<span ')[1:]]]\n",
    "        \n",
    "        if i == 1:\n",
    "            # Skip first row because they are column headers\n",
    "            i += 1\n",
    "            continue\n",
    "        elif i == end_row:\n",
    "            break\n",
    "        else:\n",
    "            # Append necessary items to initialized lists for \n",
    "            # dataframe storage\n",
    "            close = float(row_items[5].replace(',',''))\n",
    "        i += 1\n",
    "    \n",
    "    # Return dataframe of necessary values\n",
    "    return np.round(np.float(close),2)\n",
    "\n",
    "def last_close(ticker):\n",
    "    alphavantage_link = 'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol={0}&apikey=5HZEUI5AFJB06BUK&datatype=csv&outputsize=compact'.format(ticker)\n",
    "    stockframe = pd.read_csv(alphavantage_link, index_col = 0).sort_index().tail(1)['close']\n",
    "    \n",
    "    return stockframe\n",
    "\n",
    "# Function for calculating standard dev and price moves in terms of standard dev\n",
    "# DF[[Adj Close]] Rolling Period --> DF[['Daily Vol','Daily Price Vol','Price Dev','Annual Vol']]\n",
    "def price_devs(ticker, lookbackwindow, rollingperiod):\n",
    "    # Define which online source one should use\n",
    "    data_source = 'yahoo'\n",
    "    \n",
    "    end = dt.datetime.today()\n",
    "    start_date = end - dt.timedelta(days = lookbackwindow)\n",
    "    \n",
    "    # User pandas_reader.data.DataReader to load the desired data. As simple as that.\n",
    "    df = datareader.DataReader([ticker], data_source, start_date, end).sort_index()\n",
    "\n",
    "    # Getting just the adjusted closing prices. This will return a Pandas DataFrame\n",
    "    # The index in this DataFrame is the major index of the panel_data.\n",
    "    df = df.ix['Close'].sort_index()\n",
    "    \n",
    "    df.columns = ['prices']\n",
    "    df['prices_delta'] = df.prices - df.prices.shift(1)\n",
    "    df['log_returns'] = np.log(df.prices) - np.log(df.prices.shift(1))\n",
    "    df['daily_vol'] = st.rolling_std(df.log_returns, rollingperiod, ddof = 1)\n",
    "    df['daily_vol_dollar'] = df.daily_vol*df.prices\n",
    "    df['price_dev'] = df.prices_delta/df.daily_vol_dollar.shift(1)\n",
    "    df['annual_vol'] = df.daily_vol*np.sqrt(252)\n",
    "    return df\n",
    "\n",
    "\n",
    "'''\n",
    "Function for getting all relevant earnings for a given starting week (Monday in dt.datetime(YYYY, m, d) format)\n",
    "Returns a dataframe with the earnings names, implied move, price, and earnings times.\n",
    "'''\n",
    "def weekly_earnings_check(start_datetime, days_forward):\n",
    "\n",
    "    start_date = start_datetime\n",
    "\n",
    "    weekly_earnings = []\n",
    "    while start_date.weekday() < days_forward:\n",
    "        temp_earnings = yahoo_earnings(start_date)\n",
    "        temp_earnings['Earnings Date'] = start_date\n",
    "        temp_earnings['Last Close'] = 0\n",
    "        for idx, row in temp_earnings.iterrows():\n",
    "            temp_earnings.loc[idx, 'Last Close'] = latest_yahoo(row['Tickers'])\n",
    "        weekly_earnings.append(temp_earnings)\n",
    "        start_date = start_date + dt.timedelta(1)\n",
    "\n",
    "    earnings_df = pd.concat(weekly_earnings,axis = 0, ignore_index = True)\n",
    "    earnings_df = earnings_df[earnings_df['Last Close'] >= 30]\n",
    "    earnings_df['Implied Move Weekly'] = pd.to_numeric(earnings_df['Implied Move Weekly'])\n",
    "    #earnings_df = earnings_df[earnings_df['Call Times'] != '-']\n",
    "    earnings_df['Lower Bound'] = np.round(earnings_df['Last Close']*(1 - earnings_df['Implied Move Weekly']/100),2)\n",
    "    earnings_df = earnings_df.sort_values(['Earnings Date','Call Times'])\n",
    "    \n",
    "    return earnings_df\n",
    "\n",
    "'''\n",
    "Function for pulling options data from yahoo Input is a string, either 'call' or 'put' to\n",
    "determine the contract type to pull from yahoo finance. The output is a dataframe of the latest\n",
    "data from yahoo finance tagged with the current date-time. Output columns are pull date-time,\n",
    "contract name, strike, last price, bid, ask volume, open interest, and IV (in decimal form).\n",
    "'''\n",
    "def yahoo_options(contract = 'put', ticker = 'SPX'):\n",
    "    # Using request to ping yahoo and retrieve the raw html\n",
    "    # tables for calls and puts data for gspc\n",
    "    if ticker == 'SPX':\n",
    "        site = 'https://finance.yahoo.com/quote/%5EGSPC/options?p=%5EGSPC'\n",
    "    else:\n",
    "        site = 'https://finance.yahoo.com/quote/{0}/options?p={0}&straddle=false'.format(ticker)\n",
    "    res = requests.get(site)\n",
    "    soup = bs(res.text, 'lxml')\n",
    "    calls = soup.find_all('table')[0]\n",
    "    puts = soup.find_all('table')[1]\n",
    "    if contract == 'call':\n",
    "        table = calls\n",
    "    else:\n",
    "        table = puts\n",
    "        \n",
    "    # parsing calls table\n",
    "    \n",
    "    # initiating data lists for storing column data\n",
    "    dates = []\n",
    "    names = []\n",
    "    strikes = []\n",
    "    lprices = []\n",
    "    bids = []\n",
    "    asks = []\n",
    "    volumes = []\n",
    "    open_interests = []\n",
    "    iv = []\n",
    "    current_time = dt.datetime.now()\n",
    "    \n",
    "    # starting with counter i so that the first row in the\n",
    "    # specified table is noted as the header row\n",
    "    i = 1\n",
    "    for row in table.find_all('tr'):\n",
    "        rowstring = str(row).split('\\n')\n",
    "        # if first row, store data as header labels for dataframe use\n",
    "        if i == 1:\n",
    "            header = [data.split('>')[1] for data in \\\n",
    "                        [rawstring.split('</span>')[0] for \\\n",
    "                         rawstring in rowstring[0].split('<span')[1:]]]\n",
    "        else:\n",
    "        # parsing other raw row strings to retrieve necessary data and append them\n",
    "        # to their corresponding list.\n",
    "            row_data = rowstring[0].split('data-reactid=')[3:]\n",
    "            dates.append(current_time)\n",
    "            names.append(row_data[0].split('title=\"')[1].split('\"')[0])\n",
    "            strikes.append(float(row_data[3].split('</a>')[0].split('>')[1].replace(',','')))\n",
    "            lprices.append(float(row_data[4].split('</td>')[0].split('>')[1].replace(',','')))\n",
    "            bids.append(float(row_data[5].split('</td>')[0].split('>')[1].replace(',','')))\n",
    "            asks.append(float(row_data[6].split('</td>')[0].split('>')[1].replace(',','')))\n",
    "            volumes.append(float(row_data[-3].split('</td>')[0].split('>')[1].replace(',','')))\n",
    "            open_interests.append(float(row_data[-2].split('</td>')[0].split('>')[1].replace(',','')))\n",
    "            iv.append(float(row_data[-1].split('</td>')[0].split('>')[1].replace(',','').replace('%',''))/100)\n",
    "        i += 1\n",
    "\n",
    "    return pd.DataFrame({'Pull Date': dates,\n",
    "                          contract + ' ' + header[0]: names,\n",
    "                          header[2]: strikes,\n",
    "                          header[3]: lprices,\n",
    "                          header[4]: bids,\n",
    "                          header[5]: asks,\n",
    "                          header[-3]: volumes,\n",
    "                          header[-2]: open_interests,\n",
    "                          header[-1]: iv})\n",
    "\n",
    "def fundamentals(ticker):\n",
    "\n",
    "    site = 'https://finance.yahoo.com/quote/{0}?p={0}'.format(ticker)\n",
    "\n",
    "    res = requests.get(site)\n",
    "    soup = bs(res.text, 'lxml')\n",
    "    table = soup.find_all('table')[1]\n",
    "    sum_dict = {}\n",
    "\n",
    "    # Looping through the soup lxml text table format\n",
    "    # and splitting each row as a individual string\n",
    "    # and parsing string to retrieve the date,\n",
    "    # open, and close information.\n",
    "\n",
    "\n",
    "    for row in table.find_all('tr'):\n",
    "        # Individual row stores current row item and delimits on '\\n'\n",
    "        individual_row = str(row).split('\\n')[0]\n",
    "\n",
    "        # row_items is parsed string for each current row where each\n",
    "        # item in list is the date, open, high, low, close, and volume\n",
    "        row_items = individual_row.split('<span data-reactid=')[1].split('\"><!-- react-text: ')\n",
    "        if len(row_items) > 1:\n",
    "            sum_item = row_items[0].split('>')[1].split('<')[0]\n",
    "            sum_value = row_items[1].split('-->')[1].split('<')[0]\n",
    "        elif 'YIELD' in row_items[0]:\n",
    "            try:\n",
    "                temp_val = row_items[0].split('-value\">')[1].split(\"</td>\")[0]\n",
    "                div_amount = float(temp_val.split(' ')[0])\n",
    "                div_yield = float(temp_val.split(' ')[1].replace('(','').replace(')','').replace('%',''))\n",
    "\n",
    "                sum_dict['Div'] = div_amount\n",
    "                sum_dict['Yield'] = div_yield\n",
    "            except:\n",
    "                sum_dict['Div'] = np.nan\n",
    "                sum_dict['Yield'] = np.nan\n",
    "\n",
    "        sum_dict[sum_item] = sum_value\n",
    "\n",
    "    return pd.DataFrame(sum_dict, index = [ticker])\n",
    "\n",
    "# Function to return fundametal data of a ticker list\n",
    "def get_fundas(ticker_lst):\n",
    "    fund_lst = []\n",
    "    for tick in ticker_lst:\n",
    "        fund_lst.append(fundamentals(tick))\n",
    "    return pd.concat(fund_lst,axis = 0)\n",
    "\n",
    "# Function to pull straddled view of options of a ticker\n",
    "\n",
    "def get_option_chain(ticker):\n",
    "    putframe = yahoo_options(contract = 'put', ticker = ticker)\n",
    "    callframe = yahoo_options(contract = 'call', ticker = ticker)\n",
    "    calls = callframe[['Ask','Bid','Implied Volatility','Last Price','Open Interest','Strike','Volume']]\n",
    "    puts = putframe[['Ask','Bid','Implied Volatility','Last Price','Open Interest','Strike','Volume']]\n",
    "    return puts.merge(calls, how = 'inner', on = 'Strike', suffixes=('_C', '_P'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Table\n",
      "No Table\n",
      "No Table\n",
      "No Table\n",
      "No Table\n",
      "No Table\n",
      "No Table\n",
      "No Table\n",
      "No Table\n",
      "No Table\n",
      "No Table\n",
      "No Table\n",
      "No Table\n",
      "No Table\n",
      "No Table\n",
      "No Table\n",
      "No Table\n",
      "No Table\n",
      "No Table\n",
      "No Table\n",
      "No Table\n",
      "No Table\n",
      "No Table\n",
      "No Table\n",
      "No Table\n"
     ]
    }
   ],
   "source": [
    "q3_earnings_weeks = [dt.datetime(2018,7,16), dt.datetime(2018,7,23), dt.datetime(2018,7,30)]\n",
    "\n",
    "may14_earnings = weekly_earnings_check(dt.datetime(2018,5,14), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Call Times</th>\n",
       "      <th>Current 7 Day Implied</th>\n",
       "      <th>EPS</th>\n",
       "      <th>Implied Move Weekly</th>\n",
       "      <th>Tickers</th>\n",
       "      <th>Earnings Date</th>\n",
       "      <th>Last Close</th>\n",
       "      <th>Lower Bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Before Market Open</td>\n",
       "      <td>3.90</td>\n",
       "      <td>0.45</td>\n",
       "      <td>11.17</td>\n",
       "      <td>DKS</td>\n",
       "      <td>2018-05-14</td>\n",
       "      <td>31.77</td>\n",
       "      <td>28.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>After Market Close</td>\n",
       "      <td>4.01</td>\n",
       "      <td>0.65</td>\n",
       "      <td>5.01</td>\n",
       "      <td>CSCO</td>\n",
       "      <td>2018-05-16</td>\n",
       "      <td>45.98</td>\n",
       "      <td>43.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>After Market Close</td>\n",
       "      <td>2.36</td>\n",
       "      <td>0.46</td>\n",
       "      <td>6.26</td>\n",
       "      <td>CRM</td>\n",
       "      <td>2018-05-16</td>\n",
       "      <td>130.38</td>\n",
       "      <td>122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>After Market Close</td>\n",
       "      <td>4.86</td>\n",
       "      <td>1.14</td>\n",
       "      <td>6.48</td>\n",
       "      <td>AMAT</td>\n",
       "      <td>2018-05-17</td>\n",
       "      <td>54.98</td>\n",
       "      <td>51.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Call Times Current 7 Day Implied   EPS  Implied Move Weekly  \\\n",
       "0  Before Market Open                  3.90  0.45                11.17   \n",
       "3  After Market Close                  4.01  0.65                 5.01   \n",
       "4  After Market Close                  2.36  0.46                 6.26   \n",
       "5  After Market Close                  4.86  1.14                 6.48   \n",
       "\n",
       "  Tickers Earnings Date  Last Close  Lower Bound  \n",
       "0     DKS    2018-05-14       31.77        28.22  \n",
       "3    CSCO    2018-05-16       45.98        43.68  \n",
       "4     CRM    2018-05-16      130.38       122.22  \n",
       "5    AMAT    2018-05-17       54.98        51.42  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "may14_earnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp\n",
       "2018-05-11    1098.26\n",
       "Name: close, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_close('GOOG').tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
