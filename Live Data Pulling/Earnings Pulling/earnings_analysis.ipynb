{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trading Testing\n",
    "\n",
    "Testing delta probability for weeklies and monthlies\n",
    "    - Does delta match probability of occurrence\n",
    "    - Check Kelly criterion for long straddles/delta neutral back ratios\n",
    "        - To calculate expected losses and gains, use options pricing module to interpolate prices at given percentage\n",
    "        moves and use the normal pdf as the probability weightings\n",
    "    \n",
    "Check earnings returns post announcement factors\n",
    "    - Factors:\n",
    "        - Number of times beaten earnings (Dummy Variable)\n",
    "        - Consecutive earnings beats\n",
    "        - Consecutive earnings upsets\n",
    "        - 3 Month Trend before earnings\n",
    "        - YTD Trend\n",
    "        - Momentum of monthly returns (20 day, 60 day)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "--- 0.0009984970092773438 seconds ---\n"
=======
      "--- 0.0010287761688232422 seconds ---\n"
>>>>>>> f5b8fcbead30ada3dd465217ae0b00df40f1513a
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas_datareader.data import Options\n",
    "from py_vollib.black_scholes_merton.implied_volatility import *\n",
    "# ts = TimeSeries(key='5HZEUI5AFJB06BUK',output_format='pandas')\n",
    "import py_vollib\n",
    "from py_vollib.black_scholes_merton.implied_volatility import *\n",
    "from py_vollib.black_scholes_merton.greeks.analytical import *\n",
    "import plotly\n",
    "import os\n",
    "import pandas_market_calendars as mcal\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import urllib.request as req\n",
    "import time\n",
    "nyse = mcal.get_calendar('NYSE')\n",
    "from helpers import *\n",
    "\n",
    "from scipy.stats import norm as norm\n",
    "from yahoo_query import *\n",
    "# '''\n",
    "# functions list:\n",
    "    \n",
    "#     maturities(dt.datetime()) --> [float(front_wgt), float(back_wgt)]\n",
    "    \n",
    "#     optionslam_scrape(str[ticker]) --> dict[earnings]\n",
    "    \n",
    "#     yahoo_table_parse(str[raw_html_table]) --> DataFrame[ticker]\n",
    "    \n",
    "#     yahoo_earnings(dt.datetime()) --> DataFrame[earnings_on_date]\n",
    "    \n",
    "#     fundamentals(str[ticker]) --> DataFrame[stock_fundamentals]\n",
    "    \n",
    "#     get_fundas(list[ticker_lst]) --> DataFrame[stock_fundamentals]\n",
    "    \n",
    "#     historical_data(str[ticker], int[day_number], int[rolling_window], outsize[str]) --> DataFrame[daily_stock_data]\n",
    "    \n",
    "#     current_volatility(list[ticker_lst], int[roll]) --> DataFrame[stock_volatilities]\n",
    "    \n",
    "#     all_options(str[ticker], bool[greeks]) --> DataFrame[options_chains]\n",
    "    \n",
    "#     earnings_condor(str[ticker], int[max_gap], int[dte_thresh], float[|money_thresh| <= 1]) -- DataFrame[condors], DataFrame[puts], DataFrame[calls]\n",
    "    \n",
    "#     write_excel(str[filename], list[str[sheetnames]], list[dataframes]) --> void()\n",
    "    \n",
    "#     curr_stock_data(str[ticker]) --> DataFrame[stock_info]\n",
    "    \n",
    "#     curr_batch_quotes(list_of_string[tickers]) --> DataFrame[stock_info]\n",
    "\n",
    "#     past_earnings(str[ticker]) --> DataFrame[earnings_info]\n",
    "\n",
    "#     earnings_history(str[ticker]) --> [DataFrame[earnings_estimate], DataFrame[past_earnings], DataFrame[earnings_estimate_change]]\n",
    "    \n",
    "#     av_data(str[ticker]) --> DataFrame[ticker_open, ticker_close]\n",
    "\n",
    "#     av_batch(list_of_str[tickers]) --> DataFrame[tickers_closes]\n",
    "\n",
    "#     check_mkt_corr(int[corr_rolling_window],int[plot_window]) --> DataFrame[rolling_corr]\n",
    "\n",
    "#     vvix_check() --> DataFrame[VVIX Data]\n",
    "\n",
    "#     earnings_longs(list_of_str[ticker], float[bid_ask_spread]) --> DataFrame[option_chains]\n",
    "\n",
    "#     all_options_v2(str[ticker], int[dte_ub], int[dte_lb], float[moneyness]) --> DataFrame[option_chains]\n",
    "\n",
    "#     yahoo_options_query(str[ticker], int[dte_ub], int[dte_lb]) --> DataFrame[option_chains]\n",
    "\n",
    "#     greek_calc(DataFrame[option_chain], str[prem_price_use], str[day_format], float[interest_rate], float[dividend_rate])\n",
    "\n",
    "#     price_sim(DataFrame[options_df], float[price_change], float[vol_change], int[days_change], str[output = 'All'],\n",
    "#               str[skew = 'flat'], str[day_format = 'trading'], float[interest_rate = 0.0193], float[dividend_rate = 0],\n",
    "#               float[prem_price_use = 'Mid'])\n",
    "\n",
    "\n",
    "#     position_sim(DataFrame[position_df], list_of_int[holdings], int[shares],\n",
    "#                  float[price_change], float[vol_change], int[dte_change], str[output = 'All'],\n",
    "#                  str[skew = 'flat'], str[prem_price_use = 'Mid'], str[day_format = 'trading'], \n",
    "#                  float[interest_rate = 0.0193], float[dividend_rate = 0])\n",
    "\n",
    "#     yahoo_fundamentals(list_of_str[tickers]) --> DataFrame[fundamentals]\n",
    "\n",
    "# '''\n",
    "\n",
    "stock_list = pd.read_csv('optionablestocks.csv')\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "def pull_data(ticker):\n",
    "    yahoo_data = yahoo_query(ticker,dt.datetime(2018,1,1))\n",
    "    yahoo_data.full_info_query()\n",
    "    earnings_info = yahoo_data.earnings_history.join(yahoo_data.cashFlowStatementQuarter).join(yahoo_data.incomeStatementQuarter.drop(['netIncome','maxAge'],\n",
    "                                                                                                                                      axis = 1),\n",
    "                                                                                               rsuffix='_income').join(yahoo_data.balanceSheetQuarter,\n",
    "                                                                                                                       rsuffix = '_balance')\n",
    "    earnings_info['earnBeatsBefore'] = 0\n",
    "    earnings_info['earnMissBefore'] = 0\n",
    "\n",
    "    for idx, row in earnings_info.iterrows():\n",
    "        earnings_info.loc[idx,'earnBeatsBefore'] = len(earnings_info[(earnings_info.index <= idx) & (earnings_info.epsDifference > 0)])\n",
    "        earnings_info.loc[idx,'earnMissBefore'] = len(earnings_info[(earnings_info.index <= idx) & (earnings_info.epsDifference <= 0)])\n",
    "    earnings_info = earnings_info.shift(1)\n",
    "\n",
    "\n",
    "    earnings_moves = past_earnings(ticker).sort_index()\n",
    "    earnings_moves = earnings_moves[(earnings_moves.index > min(yahoo_data.earnings_history.index) - dt.timedelta(days = 92)) &\n",
    "                                    (earnings_moves.index <= max(yahoo_data.earnings_history.index))].sort_index()\n",
    "    \n",
    "    \n",
    "    earnings_df = pd.concat([earnings_info.reset_index(), \n",
    "                             earnings_moves.reset_index()], axis = 1)\n",
    "    earnings_df.columns = ['quarter' if col == 'index' else col for col in earnings_df.columns.tolist()]\n",
    "    earnings_df['Underlying'] = ticker\n",
    "\n",
    "    ### separate df for current key measures\n",
    "    keyMetrics = yahoo_data.profile.join(yahoo_data.keyStats).join(yahoo_data.finData, rsuffix = '_finData')\n",
    "    \n",
    "    return (earnings_df, keyMetrics)\n",
    "\n",
    "def download_yahoo_data(ticker_list, retries = 10):\n",
    "\n",
    "    earnings_lst = []\n",
    "    keyStats_lst = []\n",
    "\n",
    "    item_counter = 0\n",
    "    total_length = len(ticker_list)\n",
    "    failed_list = []\n",
    "\n",
    "    for ticker in ticker_list:\n",
    "        try:\n",
    "            curr_earnings, curr_keyStats = pull_data(ticker)\n",
    "            earnings_lst.append(curr_earnings)\n",
    "            keyStats_lst.append(curr_keyStats)\n",
    "            print('Accepted: {}'.format(ticker))\n",
    "        except:\n",
    "            for i in range(retries):\n",
    "                try:\n",
    "                    curr_earnings, curr_keyStats = pull_data(ticker)\n",
    "                    earnings_lst.append(curr_earnings)\n",
    "                    keyStats_lst.append(curr_keyStats)\n",
    "                    print('Accepted: {}'.format(ticker))\n",
    "                except:\n",
    "                    continue\n",
    "            print('Failed: {}'.format(ticker))\n",
    "            failed_list.append(ticker)\n",
    "\n",
    "        item_counter += 1\n",
    "        print(\"{0:.2f}% Completed\".format(item_counter/total_length*100))\n",
    "        print(\"{} total failures\".format(len(failed_list)))\n",
    "        \n",
    "    earnings_df = pd.concat(earnings_lst, axis = 0)\n",
    "    earnings_df = earnings_df.reset_index()[earnings_df.columns]\n",
    "    keyStats_df = pd.concat(keyStats_lst, axis = 0)\n",
    "        \n",
    "    return earnings_df, keyStats_df, failed_list\n",
    "\n",
    "def fin_ratios(earnings_df):\n",
    "    \n",
    "    ratios_df = earnings_df[['Underlying','timestamp','quarter','1Year', '1month', '3month', '6month', \n",
    "                             'PostEarningsReturn','industry', 'sector']]\n",
    "    \n",
<<<<<<< HEAD
    "    '''\n",
    "    ['totalCurrentAssets','totalCurrentLiabilities','totalStockholderEquity',\n",
    "     'netReceivables','totalRevenue','totalLiab','totalAssets','grossProfit',\n",
    "     'operatingIncome','ebit','netIncome','changeInCash','cash','changeToLiabilities',\n",
    "     'changeToNetincome','changeToOperatingActivities','totalCashFromOperatingActivities']\n",
    "    '''\n",
=======
>>>>>>> f5b8fcbead30ada3dd465217ae0b00df40f1513a
    "    # Solvency Ratios\n",
    "    # ratios_df['quick_ratio'] = (earnings_df.totalCurrentAssets - earnings_df.inventory)/earnings_df.totalCurrentLiabilities\n",
    "    ratios_df['current_ratio'] = earnings_df.totalCurrentAssets/earnings_df.totalCurrentLiabilities\n",
    "    ratios_df['total_debt_equity_ratio'] = earnings_df.totalCurrentLiabilities/earnings_df.totalStockholderEquity\n",
    "    # ratios_df['longterm_debt_equity_ratio'] = earnings_df.longTermDebt/earnings_df.totalStockholderEquity\n",
    "    \n",
    "    # Liquidity Ratios\n",
    "    ratios_df['day_sales_outstanding'] = 365*(earnings_df.netReceivables/earnings_df.totalRevenue)\n",
    "    # ratios_df['day_inventory_outstanding'] = 365*(earnings_df.inventory/earnings_df.costOfRevenue)\n",
    "#     ratios_df['day_payable_outstanding'] = 365*(earnings_df.accountsPayable/earnings_df.costOfRevenue)\n",
    "#     ratios_df['cash_conversion'] = ratios_df.day_sales_outstanding + ratios_df.day_inventory_outstanding - ratios_df.day_inventory_outstanding\n",
    "#     ratios_df['intangibles_of_book'] = earnings_df.intangibleAssets/earnings_df.totalStockholderEquity\n",
    "#     ratios_df['inventory_of_revenue'] = earnings_df.inventory/earnings_df.totalRevenue\n",
    "    \n",
    "#     # Capital Structure Ratios\n",
    "#     ratios_df['ltdebt_of_invested'] = earnings_df.longTermDebt/earnings_df.investments\n",
    "#     ratios_df['stdebt_of_invested'] = earnings_df.shortLongTermDebt/earnings_df.investments\n",
    "#     ratios_df['ltdebt_to_totaldebt'] = earnings_df.longTermDebt/earnings_df.totalLiab\n",
    "#     ratios_df['stdebt_to_totaldebt'] = earnings_df.shortLongTermDebt/earnings_df.totalLiab\n",
    "    ratios_df['total_liabilities_total_assets'] = earnings_df.totalLiab/earnings_df.totalAssets\n",
    "\n",
    "    # Income Statement Ratios\n",
    "    ratios_df['gross_margin'] = earnings_df.grossProfit/earnings_df.totalRevenue\n",
    "    #ratios_df['rd_to_sales'] = earnings_df.researchDevelopment/earnings_df.totalRevenue\n",
    "    ratios_df['operating_margin'] = earnings_df.operatingIncome/earnings_df.totalRevenue\n",
    "    ratios_df['interest_coverage_ratio'] = earnings_df.ebit/earnings_df.totalRevenue\n",
    "    ratios_df['net_profit_margin'] = earnings_df.netIncome/earnings_df.totalRevenue\n",
    "    ratios_df['roe'] = (earnings_df.totalRevenue - earnings_df.totalOperatingExpenses)/earnings_df.totalRevenue\n",
    "\n",
    "    # Cash Flow Ratios\n",
    "    ratios_df['changeInCash'] = earnings_df.changeInCash/earnings_df.cash\n",
    "    ratios_df['changeToLiabilities'] = earnings_df.changeToLiabilities/earnings_df.totalLiab\n",
    "    #ratios_df['changeToInventory'] = earnings_df.changeToInventory/earnings_df.inventory\n",
    "    ratios_df['changeToNetincome'] = earnings_df.changeToNetincome/earnings_df.netIncome\n",
    "    ratios_df['changeToOperatingActivities'] = earnings_df.changeToOperatingActivities/earnings_df.totalCashFromOperatingActivities\n",
    "    \n",
    "    return_levels = []\n",
    "    for postreturn in ratios_df.PostEarningsReturn.tolist():\n",
    "        if postreturn > 0.04:\n",
    "            value = 'up'\n",
    "        elif postreturn < -0.04:\n",
    "            value = 'down'\n",
    "        else:\n",
    "            value = 'flat'\n",
    "        return_levels.append(value)\n",
    "        \n",
    "    ratios_df['return_factor'] = return_levels\n",
    "    \n",
    "    return ratios_df.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    \n",
    "# earnings_df, keyMetrics = pull_data('AMD')\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial Ratios\n",
    "\n",
    "## Solvency Ratios\n",
    "\n",
    "- quick_ratio = (totalCurrentAssets - inventory)/totalCurrentLiabilities\n",
    "- current_ratio = totalCurrentAssets/totalCurrentLiabilities\n",
    "- total_debt_equity_ratio = totalCurrentLiabilities/totalStockholderEquity\n",
    "- longterm_debt_equity_ratio = longTermDebt/totalStockholderEquity\n",
    "- shortterm_debt_equity_ratio = shortLongTermDebt/totalStockholderEquity *\n",
    "\n",
    "## Liquidity Ratios\n",
    "- day_sales_outstanding = 365*(netReceivables/totalRevenue)\n",
    "- day_inventory_outstanding = 365*(inventory/costOfRevenue)\n",
    "- day_payable_outstanding = 365*(accountsPayable/costOfRevenue)\n",
    "- cash_conversion = day_sales_outstanding + day_inventory_outstanding - day_inventory_outstanding\n",
    "- intangibles_of_book = intangibleAssets/totalStockholderEquity\n",
    "- inventory_of_revenue = inventory/totalRevenue\n",
    "\n",
    "## Capital Structure Ratios\n",
    "- ltdebt_of_invested = longTermDebt/investments\n",
    "- stdebt_of_invested = shortLongTermDebt/investments\n",
    "- ltdebt_to_totaldebt = longTermDebt/totalLiab\n",
    "- stdebt_to_totaldebt = shortLongTermDebt/totalLiab\n",
    "- total_liabilities_total_assets = totalLiab/totalAssets\n",
    "\n",
    "## Income Statement Ratios\n",
    "- gross_margin = grossProfit/totalRevenue\n",
    "- rd_to_sales = researchDevelopment/totalRevenue\n",
    "- operating_margin = operatingIncome/totalRevenue\n",
    "- interest_coverage_ratio = ebit/totalRevenue\n",
    "- net_profit_margin = netIncome/totalRevenue\n",
    "- roe = (totalRevenue - totalOperatingExpenses)/totalRevenue\n",
    "\n",
    "## Cash Flow Ratios\n",
    "- changeInCash = changeInCash/cash\n",
    "- changeToLiabilities = changeToLiabilities/totalLiab\n",
    "- changeToInventory = changeToInventory/inventory\n",
    "- changeToNetincome = changeToNetincome/netIncome\n",
    "- changeToOperatingActivities = changeToOperatingActivities/totalCashFromOperatingActivities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#earnings_testing = earnings_df.dropna(subset = ['1Year','1month','3month','6month']).reset_index()[earnings_df.columns]\n",
    "\n",
    "earnHist = pd.read_csv('earningsHist.csv', index_col = 0)\n",
    "keyStats = pd.read_csv('keyStats.csv', index_col = 0)\n",
    "sectors = keyStats[['industry','sector']]\n",
    "sectors['Underlying'] = sectors.index\n",
    "\n",
    "earnings = pd.merge(earnHist, sectors.reset_index()[sectors.columns],\n",
    "                    on=['Underlying'], \n",
    "                    how='left').drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# earnings = fin_ratios(earnings).dropna()\n",
    "\n",
    "# earnings['next_q'] = pd.to_datetime(earnings.quarter) + dt.timedelta(days = 92)\n",
    "# earnings['prev_q'] = pd.to_datetime(earnings.quarter) - dt.timedelta(days = 92)\n",
    "\n",
    "# earnings = earnings[(pd.to_datetime(earnings.timestamp) >= earnings['prev_q']) &\n",
    "#                     (pd.to_datetime(earnings.timestamp) <= earnings['next_q'])].reset_index(drop = True)\n",
    "\n",
    "# earnings[['Underlying','epsPos','epsNeg','quarter']]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 18,
>>>>>>> f5b8fcbead30ada3dd465217ae0b00df40f1513a
   "metadata": {},
   "outputs": [],
   "source": [
    "# ticker = 'AAPL'\n",
    "# yahoo_data = yahoo_query(ticker,dt.datetime(2018,1,1))\n",
    "# yahoo_data.full_info_query()\n",
    "# earnings_info = yahoo_data.earnings_history.join(yahoo_data.cashFlowStatementQuarter).join(yahoo_data.incomeStatementQuarter.drop(['netIncome','maxAge'],\n",
    "#                                                                                                                                   axis = 1),\n",
    "#                                                                                            rsuffix='_income').join(yahoo_data.balanceSheetQuarter,\n",
    "#                                                                                                                    rsuffix = '_balance')\n",
    "\n",
    "# earnings_moves = past_earnings(ticker).sort_index()\n",
    "# earnings_moves = earnings_moves[(earnings_moves.index > min(yahoo_data.earnings_history.index) - dt.timedelta(days = 92)) &\n",
    "#                                 (earnings_moves.index <= max(yahoo_data.earnings_history.index))].sort_index()\n",
    "\n",
<<<<<<< HEAD
    "# earnings_df = pd.concat([earnings_info.reset_index(), \n",
    "#                          earnings_moves.reset_index()], axis = 1)\n",
    "# earnings_df.columns = ['quarter' if col == 'index' else col for col in earnings_df.columns.tolist()]\n",
    "# earnings_df['Underlying'] = ticker\n",
    "\n",
    "# ### separate df for current key measures\n",
    "# keyMetrics = yahoo_data.profile.join(yahoo_data.keyStats).join(yahoo_data.finData, rsuffix = '_finData')\n",
    "\n",
    "# earnings_df, keyStats_df, failed_list = download_yahoo_data(stock_list['OPTION SYMBOL'].tolist(), retries = 10)\n",
    "#earnings_df2, keyStats_df2, failed_list2 = download_yahoo_data(failed_list, retries = 10)\n",
    "\n",
    "#output = earnings[['totalCurrentAssets','totalCurrentLiabilities','totalStockholderEquity',\n",
    "#          'netReceivables','totalRevenue','totalLiab','totalAssets','grossProfit',\n",
    "#          'operatingIncome','ebit','netIncome','changeInCash','cash','changeToLiabilities',\n",
    "#          'changeToNetincome','changeToOperatingActivities','totalCashFromOperatingActivities',\n",
    "#          'quarter','industry', 'sector', 'Underlying','timestamp','PostEarningsReturn',\n",
    "#          'earnBeatsBefore','earnMissBefore','1Year','1month','3month','6month']]\n",
    "\n",
    "# fin_ratios(output)"
=======
    "# # earnings_df = pd.concat([earnings_info.reset_index(), \n",
    "# #                          earnings_moves.reset_index()], axis = 1)\n",
    "# # earnings_df.columns = ['quarter' if col == 'index' else col for col in earnings_df.columns.tolist()]\n",
    "# # earnings_df['Underlying'] = ticker\n",
    "\n",
    "# # ### separate df for current key measures\n",
    "# # keyMetrics = yahoo_data.profile.join(yahoo_data.keyStats).join(yahoo_data.finData, rsuffix = '_finData')\n",
    "\n",
    "# # earnings_df, keyStats_df, failed_list = download_yahoo_data(stock_list['OPTION SYMBOL'].tolist(), retries = 10)\n",
    "# earnings_df2, keyStats_df2, failed_list2 = download_yahoo_data(failed_list, retries = 10)\n"
>>>>>>> f5b8fcbead30ada3dd465217ae0b00df40f1513a
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ks = pd.read_csv('long_names.csv', index_col = 0)\n",
    "\n",
    "\n",
    "# day_number = 300\n",
    "# roll_window = 20\n",
    "\n",
    "# returns_lst = []\n",
    "# for ticker in ks.index.tolist():\n",
    "    \n",
    "#     requesting = True\n",
    "#     while requesting:\n",
    "#         try:\n",
    "#             curr_prices = historical_data(ticker, day_number, roll_window, 'full')[['close']]\n",
    "#             curr_prices['1year'] = curr_prices.close.pct_change(252)\n",
    "#             curr_prices['6month'] = curr_prices.close.pct_change(126)\n",
    "#             curr_prices['3month'] = curr_prices.close.pct_change(63)\n",
    "#             curr_prices['1month'] = curr_prices.close.pct_change(21)\n",
    "#             curr_prices = curr_prices.tail(1)\n",
    "#             curr_prices.index = [ticker]\n",
    "#             returns_lst.append(curr_prices)\n",
    "            \n",
    "#             requesting = False\n",
    "#         except:\n",
    "#             continue\n",
    "    \n",
    "\n",
    "returns = pd.concat(returns_lst, axis = 0)\n",
    "returns.to_csv('returns.csv')"
=======
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fchen\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "C:\\Users\\fchen\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "C:\\Users\\fchen\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "C:\\Users\\fchen\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "C:\\Users\\fchen\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "C:\\Users\\fchen\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "C:\\Users\\fchen\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "C:\\Users\\fchen\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "C:\\Users\\fchen\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "C:\\Users\\fchen\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "C:\\Users\\fchen\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:36: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "C:\\Users\\fchen\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:38: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "C:\\Users\\fchen\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:39: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "C:\\Users\\fchen\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:51: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "earnings = pd.read_csv('earnHist_v2.csv').drop_duplicates().reset_index(drop = True).replace(np.inf, np.nan)\n",
    "\n",
    "earnings_df = earnings.copy()\n",
    "ratios_df = earnings[['Underlying','quarter','timestamp', 'industry', 'sector',\n",
    "                      'earnBeatsBefore', 'earnMissBefore','PostEarningsReturn','1Year',\n",
    "                      '6month','3month','1month']]\n",
    "ratios_df['current_ratio'] = earnings_df.totalCurrentAssets/earnings_df.totalCurrentLiabilities\n",
    "ratios_df['total_debt_equity_ratio'] = earnings_df.totalCurrentLiabilities/earnings_df.totalStockholderEquity\n",
    "# ratios_df['longterm_debt_equity_ratio'] = earnings_df.longTermDebt/earnings_df.totalStockholderEquity\n",
    "\n",
    "# Liquidity Ratios\n",
    "ratios_df['day_sales_outstanding'] = 365*(earnings_df.netReceivables/earnings_df.totalRevenue)\n",
    "# ratios_df['day_inventory_outstanding'] = 365*(earnings_df.inventory/earnings_df.costOfRevenue)\n",
    "#     ratios_df['day_payable_outstanding'] = 365*(earnings_df.accountsPayable/earnings_df.costOfRevenue)\n",
    "#     ratios_df['cash_conversion'] = ratios_df.day_sales_outstanding + ratios_df.day_inventory_outstanding - ratios_df.day_inventory_outstanding\n",
    "#     ratios_df['intangibles_of_book'] = earnings_df.intangibleAssets/earnings_df.totalStockholderEquity\n",
    "#     ratios_df['inventory_of_revenue'] = earnings_df.inventory/earnings_df.totalRevenue\n",
    "\n",
    "#     # Capital Structure Ratios\n",
    "#     ratios_df['ltdebt_of_invested'] = earnings_df.longTermDebt/earnings_df.investments\n",
    "#     ratios_df['stdebt_of_invested'] = earnings_df.shortLongTermDebt/earnings_df.investments\n",
    "#     ratios_df['ltdebt_to_totaldebt'] = earnings_df.longTermDebt/earnings_df.totalLiab\n",
    "#     ratios_df['stdebt_to_totaldebt'] = earnings_df.shortLongTermDebt/earnings_df.totalLiab\n",
    "ratios_df['total_liabilities_total_assets'] = earnings_df.totalLiab/earnings_df.totalAssets\n",
    "\n",
    "# Income Statement Ratios\n",
    "ratios_df['gross_margin'] = earnings_df.grossProfit/earnings_df.totalRevenue\n",
    "#ratios_df['rd_to_sales'] = earnings_df.researchDevelopment/earnings_df.totalRevenue\n",
    "ratios_df['operating_margin'] = earnings_df.operatingIncome/earnings_df.totalRevenue\n",
    "ratios_df['interest_coverage_ratio'] = earnings_df.ebit/earnings_df.totalRevenue\n",
    "ratios_df['net_profit_margin'] = earnings_df.netIncome/earnings_df.totalRevenue\n",
    "ratios_df['roe'] = (earnings_df.totalRevenue - earnings_df.totalOperatingExpenses)/earnings_df.totalRevenue\n",
    "\n",
    "# Cash Flow Ratios\n",
    "ratios_df['changeInCash'] = earnings_df.changeInCash/earnings_df.cash\n",
    "ratios_df['changeToLiabilities'] = earnings_df.changeToLiabilities/earnings_df.totalLiab\n",
    "#ratios_df['changeToInventory'] = earnings_df.changeToInventory/earnings_df.inventory\n",
    "ratios_df['changeToNetincome'] = earnings_df.changeToNetincome/earnings_df.netIncome\n",
    "ratios_df['changeToOperatingActivities'] = earnings_df.changeToOperatingActivities/earnings_df.totalCashFromOperatingActivities\n",
    "\n",
    "return_levels = []\n",
    "for postreturn in ratios_df.PostEarningsReturn.tolist():\n",
    "    if postreturn > 0.04:\n",
    "        value = 'up'\n",
    "    elif postreturn < -0.04:\n",
    "        value = 'down'\n",
    "    else:\n",
    "        value = 'flat'\n",
    "    return_levels.append(value)\n",
    "\n",
    "ratios_df['return_factor'] = return_levels\n",
    "\n",
    "ratios_df.dropna(subset = ['changeToOperatingActivities','changeInCash']).dropna().reset_index(drop = True).to_csv('earnHist_v3.csv')"
>>>>>>> f5b8fcbead30ada3dd465217ae0b00df40f1513a
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 1.084203\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:496: ConvergenceWarning:\n",
      "\n",
      "Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'industry', 'sector'\n",
    "\n",
    "data = earnings.copy()\n",
    "data.to_csv('earnings_data.csv')\n",
    "\n",
    "\n",
    "train = earnings[pd.to_datetime(earnings.quarter) < dt.datetime(2018,3,31)]\n",
    "test = earnings[(pd.to_datetime(earnings.quarter) >= dt.datetime(2018,3,31)) &\n",
    "                (pd.to_datetime(earnings.quarter) < dt.datetime(2018,5,31))]\n",
    "validation = earnings[pd.to_datetime(earnings.quarter) >= dt.datetime(2018,5,31)]\n",
    "\n",
    "\n",
    "#%% Data Preprocessing\n",
    "# Importing the libraries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "x_cols = ['1Year', '1month', '3month','6month', 'current_ratio',\n",
    "          'total_debt_equity_ratio', 'day_sales_outstanding',\n",
    "          'total_liabilities_total_assets', 'gross_margin', 'operating_margin',\n",
    "          'interest_coverage_ratio', 'net_profit_margin', 'roe', 'changeInCash',\n",
    "          'changeToLiabilities', 'changeToNetincome',\n",
    "          'changeToOperatingActivities']\n",
    "\n",
    "# Importing the dataset\n",
    "X_train = train.loc[:, x_cols].values\n",
    "y_train = train.loc[:, 'return_factor'].values\n",
    "\n",
    "X_test = test.loc[:, x_cols].values\n",
    "y_test = test.loc[:, 'return_factor'].values\n",
    "\n",
    "X_validation = validation.loc[:, x_cols].values\n",
    "y_validation = validation.loc[:, 'return_factor'].values\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "#%% Fitting Logistic Regression to the Training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(multi_class='multinomial', solver='newton-cg').fit(X_train, y_train)\n",
    "logit_model=sm.MNLogit(y_train,X_train)\n",
    "result=logit_model.fit()\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 1.084203\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:496: ConvergenceWarning:\n",
      "\n",
      "Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1Year',\n",
       " '1month',\n",
       " '3month',\n",
       " '6month',\n",
       " 'current_ratio',\n",
       " 'total_debt_equity_ratio',\n",
       " 'day_sales_outstanding',\n",
       " 'total_liabilities_total_assets',\n",
       " 'gross_margin',\n",
       " 'operating_margin',\n",
       " 'interest_coverage_ratio',\n",
       " 'net_profit_margin',\n",
       " 'roe',\n",
       " 'changeInCash',\n",
       " 'changeToLiabilities',\n",
       " 'changeToNetincome',\n",
       " 'changeToOperatingActivities']"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "logit_model=sm.MNLogit(y_train,X_train)\n",
    "result=logit_model.fit()\n",
    "x_cols"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": 37,
   "metadata": {},
>>>>>>> f5b8fcbead30ada3dd465217ae0b00df40f1513a
   "outputs": [],
   "source": [
    "keyStats = pd.read_csv('keyStats.csv', index_col = 0)\n",
    "drop_cols = ['lastSplitDate','lastSplitFactor','fundFamily','fundInceptionDate',\n",
    " 'fiveYearAverageReturn','lastCapGain','lastDividendValue','totalAssets',      \n",
    " 'threeYearAverageReturn','annualHoldingsTurnover','priceToSalesTrailing12Months',\n",
    " 'revenueQuarterlyGrowth','beta3Year','legalType','yield','morningStarOverallRating',\n",
    " 'category','morningStarRiskRating','annualReportExpenseRatio','ytdReturn']\n",
    "keyStats = keyStats.drop(drop_cols, axis = 1).dropna()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
=======
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['52WeekChange', 'SandP52WeekChange', 'auditRisk', 'beta', 'boardRisk',\n",
       "       'bookValue', 'compensationRisk', 'currentPrice', 'currentRatio',\n",
       "       'dateShortInterest', 'debtToEquity', 'earningsGrowth',\n",
       "       'earningsQuarterlyGrowth', 'ebitda', 'ebitdaMargins',\n",
       "       'enterpriseToEbitda', 'enterpriseToRevenue', 'enterpriseValue',\n",
       "       'financialCurrency', 'floatShares', 'forwardEps', 'forwardPE',\n",
       "       'freeCashflow', 'fullTimeEmployees', 'grossMargins', 'grossProfits',\n",
       "       'heldPercentInsiders', 'heldPercentInstitutions', 'industry',\n",
       "       'lastFiscalYearEnd', 'maxAge', 'maxAge_finData', 'mostRecentQuarter',\n",
       "       'netIncomeToCommon', 'nextFiscalYearEnd', 'numberOfAnalystOpinions',\n",
       "       'operatingCashflow', 'operatingMargins', 'overallRisk', 'pegRatio',\n",
       "       'priceHint', 'priceToBook', 'profitMargins', 'profitMargins_finData',\n",
       "       'quickRatio', 'recommendationKey', 'recommendationMean',\n",
       "       'returnOnAssets', 'returnOnEquity', 'revenueGrowth', 'revenuePerShare',\n",
       "       'sector', 'shareHolderRightsRisk', 'sharesOutstanding',\n",
       "       'sharesPercentSharesOut', 'sharesShort', 'sharesShortPreviousMonthDate',\n",
       "       'sharesShortPriorMonth', 'shortPercentOfFloat', 'shortRatio',\n",
       "       'targetHighPrice', 'targetLowPrice', 'targetMeanPrice',\n",
       "       'targetMedianPrice', 'totalCash', 'totalCashPerShare', 'totalDebt',\n",
       "       'totalRevenue', 'trailingEps'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyStats.columns"
   ]
>>>>>>> f5b8fcbead30ada3dd465217ae0b00df40f1513a
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
