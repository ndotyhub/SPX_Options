{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note to import from .py files, must follow structure\n",
    "# from <.py filename excluding '.py'> import <class name>\n",
    "# Optionslam creds: aspringfastlaner Options2018\n",
    "\n",
    "# Importing necessary models\n",
    "import smtplib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import pandas.stats.moments as st\n",
    "from pandas import ExcelWriter\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as dates\n",
    "# import matplotlib.ticker as ticker\n",
    "from lxml import html\n",
    "import requests\n",
    "import webbrowser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import json\n",
    "import csv\n",
    "import sched, time\n",
    "import pandas_datareader as datareader\n",
    "from pandas_datareader.data import Options\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "ts = TimeSeries(key='5HZEUI5AFJB06BUK',output_format='pandas')\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request as urlreq\n",
    "from collections import OrderedDict\n",
    "import statsmodels.formula.api as sm\n",
    "import quandl as qd\n",
    "qd.ApiConfig.api_key = 'dzmzEExntfap7SNx5p6t'\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from pandas_datareader.data import Options\n",
    "import py_vollib\n",
    "from py_vollib.black_scholes_merton.implied_volatility import *\n",
    "from py_vollib.black_scholes_merton.greeks.analytical import *\n",
    "\n",
    "'''\n",
    "Calculate the Black-Scholes implied volatility.\n",
    "\n",
    "Parameters:\t\n",
    "price (float) – the Black-Scholes option price\n",
    "S (float) – underlying asset price\n",
    "K (float) – strike price\n",
    "t (float) – time to expiration in years\n",
    "r (float) – risk-free interest rate\n",
    "flag (str) – ‘c’ or ‘p’ for call or put.\n",
    ">>> S = 100\n",
    ">>> K = 100\n",
    ">>> sigma = .2\n",
    ">>> r = .01\n",
    ">>> flag = 'c'\n",
    ">>> t = .5\n",
    ">>> price = black_scholes(flag, S, K, t, r, sigma)\n",
    ">>> iv = implied_volatility(price, S, K, t, r, flag)\n",
    "'''\n",
    "%matplotlib inline\n",
    "\n",
    "def write_excel(filename, sheetnames, df_list):\n",
    "    # Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "    writer = pd.ExcelWriter(filename, engine='xlsxwriter')\n",
    "    for i, df in enumerate(df_list):\n",
    "        \n",
    "        df.to_excel(writer, sheet_name = sheetnames[i])\n",
    "\n",
    "    # Close the Pandas Excel writer and output the Excel file.\n",
    "    writer.save()\n",
    "    return\n",
    "\n",
    "# Alpha Vantage API Key\n",
    "# 5HZEUI5AFJB06BUK\n",
    "\n",
    "# ts = TimeSeries(key='5HZEUI5AFJB06BUK', output_format='pandas')\n",
    "# data, meta_data = ts.get_intraday(symbol='MSFT',interval='1min', outputsize='full')\n",
    "# data['close'].plot()\n",
    "# plt.title('Intraday Times Series for the MSFT stock (1 min)')\n",
    "# For intraday\n",
    "# https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY&symbol=MSFT&interval=1min&apikey=d5HZEUI5AFJB06BUK&datatype=csv\n",
    "\n",
    "# For daily\n",
    "# https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol=MSFT&apikey=5HZEUI5AFJB06BUK&datatype=csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Pulling S&P 500 Names\n",
    "'''\n",
    "\n",
    "def pull_sp500_list():\n",
    "    site = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "    res = requests.get(site)\n",
    "    soup = bs(res.text, 'lxml')\n",
    "    table = soup.find_all('table')[0]\n",
    "\n",
    "    tickers = []\n",
    "    names = []\n",
    "    gics = []\n",
    "\n",
    "    # Looping through the soup lxml text table format\n",
    "    # and splitting each row as a individual string\n",
    "    # and parsing string to retrieve the date,\n",
    "    # open, and close information.\n",
    "    i = 1\n",
    "    for row in table.find_all('tr'):\n",
    "        if i == 1:\n",
    "            i += 1\n",
    "            continue\n",
    "        # Individual row stores current row item and delimits on '\\n'\n",
    "        individual_row = str(row).split('\\n')\n",
    "        # row_items is parsed string for each current row where each\n",
    "        ticker = individual_row[1].split('\">')[-1].split('<')[0]\n",
    "        tickers.append(ticker)\n",
    "        name = individual_row[2].split('\">')[-1].split('<')[0]\n",
    "        names.append(name)\n",
    "        gic = individual_row[4].split('>')[1].split('<')[0]\n",
    "        gics.append(gic)\n",
    "\n",
    "    sp500 = pd.DataFrame({'Name': names, 'GIC': gics}, index = tickers)\n",
    "    sp500.index.name = 'Tickers'\n",
    "    return sp500\n",
    "\n",
    "#nasdaq = pd.read_csv('http://www.nasdaq.com/screening/companies-by-industry.aspx?exchange=NASDAQ&render=download', index_col = 0)[['Name','LastSale','IPOyear','Sector']]\n",
    "#nyse = pd.read_csv('http://www.nasdaq.com/screening/companies-by-industry.aspx?exchange=NYSE&render=download', index_col = 0)[['Name','LastSale','IPOyear','Sector']]\n",
    "#us_stocks = pd.concat([nyse,nasdaq], axis = 0).drop_duplicates()\n",
    "#us_stocks = us_stocks[us_stocks['LastSale'] != 'n/a']\n",
    "#us_fundamentals = get_fundas([string.replace(' ','') for string in us_stocks.index.tolist()])\n",
    "us_stocks = pd.read_csv('us_stocks.csv', index_col = 0)\n",
    "\n",
    "active_stocks = pd.read_csv('active_names.csv', index_col = 0).dropna()\n",
    "active_etfs = pd.read_csv('active_etfs.csv', index_col = 0).dropna()\n",
    "highest_ivs = pd.read_csv('highest_iv.csv', index_col = 0).dropna()\n",
    "unusual_names = pd.read_csv('unusual_names.csv', index_col = 0).dropna()\n",
    "\n",
    "unusual_names['IV'] = unusual_names['IV'].str.rstrip('%').astype('float') / 100.0\n",
    "\n",
    "# filtered_names = pd.read_csv('filtered_names.csv', index_col = 0).join(us_stocks, how = 'inner')[us_stocks.columns]\n",
    "# filtered_names['Market Cap'] = filtered_names['Market Cap'].astype(str).str[:-1]\n",
    "# filtered_names['Market Cap'] = filtered_names['Market Cap'].astype(float)\n",
    "# filtered_names = filtered_names.sort_values(['Market Cap'], ascending = False)\n",
    "\n",
    "watchlist = ['NVDA', 'FB', 'AMZN', 'NFLX', 'GOOGL', 'GOOG',\n",
    "             'TSLA', 'EA', 'ATVI', 'APPL', 'MSFT', 'INTC',\n",
    "             'V', 'CSCO', 'VZ', 'T', 'MA', 'ORCL', 'IBM',\n",
    "             'ADBE', 'TXN', 'AVGO', 'PYPL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function for pulling implied volatility from option slam for single ticker\n",
    "'''\n",
    "\n",
    "def optionslam_scrape(ticker):\n",
    "    site = 'https://www.optionslam.com/earnings/stocks/' + ticker\n",
    "    res = requests.get(site)\n",
    "    soup = bs(requests.get(site).text, \"lxml\")\n",
    "    soup = soup.prettify()\n",
    "    earnings_dict = {'Ticker': ticker}\n",
    "    \n",
    "    # Check if there's weekly options\n",
    "    curr7_implied = \"Current 7 Day Implied Movement:\"\n",
    "    implied_move_weekly = \"Implied Move Weekly:\"\n",
    "    nextearnings = \"Next Earnings Date:\"\n",
    "    if curr7_implied not in soup:\n",
    "        return 'No Weeklies'\n",
    "    \n",
    "    # Parsing if weekly options exist\n",
    "    # Next earnings date and before or after\n",
    "    earnings_start_string = \"Next Earnings Date:\"\n",
    "    earnings_end_string = '</font>'\n",
    "    raw_earnings_string = (soup.split(earnings_start_string))[1].split(earnings_end_string)[0].replace('\\n','').strip()\n",
    "    \n",
    "    try:\n",
    "        earnings_date = str((raw_earnings_string.split('<b>'))[1].split('<font size=\"-1\">')).split(\"'\")[1].strip()\n",
    "    except:\n",
    "        return 'Error Parsing'\n",
    "    \n",
    "    earnings_time = str(raw_earnings_string[-2:].strip()).strip()\n",
    "    \n",
    "    earnings_dict['Date'] = earnings_date\n",
    "    earnings_dict['Earnings Time'] = earnings_time\n",
    "    \n",
    "    # Parsing 7 day implied move if weekly option exists\n",
    "    ending_string = '<font size=\"-2\">'\n",
    "    curr_7 = (soup.split(curr7_implied))[1].split(ending_string)[0].replace('\\n','').strip(\"\").split(\"<td>\")[-1].strip()\n",
    "    earnings_dict['Current 7 Day Implied'] = curr_7\n",
    "    \n",
    "    # Parsing Weekly Implied move if weekly option exists\n",
    "    if implied_move_weekly in soup:\n",
    "        weekly_implied = (soup.split(implied_move_weekly))[1].split(ending_string)[0].replace('\\n','').strip(\"\").split(\"<td>\")[-1].strip()\n",
    "    else:\n",
    "        weekly_implied = ''\n",
    "    earnings_dict[\"Implied Move Weekly\"] = weekly_implied\n",
    "    \n",
    "    return earnings_dict\n",
    "\n",
    "# Looping through the soup lxml text table format\n",
    "# and splitting each row as a individual string\n",
    "# and parsing string to retrieve the date,\n",
    "# open, and close information.\n",
    "\n",
    "def yahoo_table_parse(raw_html_table):\n",
    "    tickers = []\n",
    "    call_times = []\n",
    "    implied_7_day = []\n",
    "    implied_weekly = []\n",
    "    eps = []\n",
    "    i = 1\n",
    "    end_row = 10\n",
    "    for row in raw_html_table.find_all('tr'):\n",
    "        # Individual row stores current row item and delimits on '\\n'\n",
    "        individual_row = str(row).split('\\n')\n",
    "        row_items = individual_row[0].split('</span>')[:3]\n",
    "\n",
    "        if i == 1:\n",
    "            i += 1\n",
    "            continue\n",
    "        tick = row_items[0].split('data-symbol=\"')[1].split('\"')[0]\n",
    "        os_check = optionslam_scrape(tick)\n",
    "\n",
    "        if type(os_check) == str:\n",
    "            continue\n",
    "        else:\n",
    "            tickers.append(tick)\n",
    "            call_times.append(row_items[0].split('data-symbol=\"')[1].split('\"')[-1].replace('>',''))\n",
    "            eps.append(row_items[1].split('</td>')[1].split('>')[1])\n",
    "            implied_7_day.append(os_check['Current 7 Day Implied'].replace('%',''))\n",
    "            implied_weekly.append(os_check['Implied Move Weekly'].replace('%',''))\n",
    "\n",
    "\n",
    "    return pd.DataFrame({'Tickers': tickers, 'Call Times': call_times, 'EPS': eps,\n",
    "                         'Current 7 Day Implied': implied_7_day,\n",
    "                         'Implied Move Weekly': implied_weekly})\n",
    "\n",
    "\n",
    "def yahoo_earnings(date):\n",
    "    # Yahoo Earnings Calendar Check\n",
    "\n",
    "    today = date.strftime('%Y-%m-%d')\n",
    "    tables = []\n",
    "    for i in range(6):\n",
    "        yahoo_url = 'https://finance.yahoo.com/calendar/earnings?day=' + today + '&offset={}&size=100'.format(int(i*100))\n",
    "        res = requests.get(yahoo_url)\n",
    "        soup = bs(requests.get(yahoo_url).text, \"lxml\")\n",
    "\n",
    "        try:\n",
    "            table = soup.find_all('table')[0]\n",
    "            tables.append(yahoo_table_parse(table))\n",
    "        except:\n",
    "            print('No Table')\n",
    "\n",
    "    return pd.concat(tables,axis = 0, ignore_index = True)\n",
    "\n",
    "'''\n",
    "Functions for pulling options data from yahoo Input is a string. The output is a dataframe of the latest\n",
    "data from yahoo finance tagged with the current date-time. Output columns are pull date-time,\n",
    "contract name, strike, last price, bid, ask volume, open interest, and IV (in decimal form).\n",
    "'''\n",
    "# Function for initial querying of yahoo data\n",
    "def yahoo_option_query(ticker, unix_date):\n",
    "    # dt.datetime.fromtimestamp(1525996800).date()\n",
    "    if unix_date == 'None':\n",
    "        yahoo_query = 'https://query1.finance.yahoo.com/v7/finance/options/{0}'.format(ticker)\n",
    "    else:\n",
    "        yahoo_query = 'https://query1.finance.yahoo.com/v7/finance/options/{0}?date={1}'.format(ticker,str(unix_date))\n",
    "        \n",
    "    response = urlreq.urlopen(yahoo_query)\n",
    "    data = json.loads(response.read().decode())['optionChain']['result'][0]\n",
    "    \n",
    "    dict_lst = []\n",
    "    for key in data.keys():\n",
    "        dict_lst.append(data[key])\n",
    "        \n",
    "    expiries = dict_lst[1]\n",
    "    strikes = dict_lst[2]\n",
    "    underlying = dict_lst[4]\n",
    "    calls = dict_lst[5][0]['calls']\n",
    "    puts = dict_lst[5][0]['puts']\n",
    "    \n",
    "    return (expiries, strikes, underlying, calls, puts)\n",
    "\n",
    "# Function for creating dataframe for options contracts for a specific maturity date\n",
    "def create_contract_df(option_dict_lst, strikes):\n",
    "    df = pd.DataFrame(columns = ['lastPrice','volume','openInterest','bid','ask','mid','impliedVolatility','expiration'],\n",
    "                      index = strikes)\n",
    "    for contract in option_dict_lst:\n",
    "        for col in df.columns:\n",
    "            if col == 'expiration':\n",
    "                df.loc[contract['strike'], col] = (dt.datetime.fromtimestamp(contract['expiration']) - dt.datetime.today()).days\n",
    "            elif col == 'mid':\n",
    "                df.loc[contract['strike'], col] = (contract['ask'] + contract['bid'])/2\n",
    "            else:\n",
    "                df.loc[contract['strike'], col] = contract[col]\n",
    "    return df.dropna()\n",
    "\n",
    "# Function for creating straddle view of options for a specific date\n",
    "def option_chain(calls, puts, strikes):\n",
    "    call_contracts = create_contract_df(calls, strikes)\n",
    "    put_contracts = create_contract_df(puts, strikes)\n",
    "    return call_contracts.join(put_contracts, how = 'inner', lsuffix='_c', rsuffix='_p')\n",
    "\n",
    "# Function for getting full option data for a specific ticker\n",
    "def pull_options(ticker):\n",
    "    initial_near_contract = yahoo_option_query(ticker, 'None')\n",
    "    \n",
    "    expiries = initial_near_contract[0]\n",
    "    options_list = [option_chain(initial_near_contract[3], initial_near_contract[4], initial_near_contract[1])]\n",
    "    \n",
    "    for expiry in expiries[1:]:\n",
    "        next_contract = yahoo_option_query(ticker, expiry)\n",
    "        options_list.append(option_chain(next_contract[3], next_contract[4], next_contract[1]))\n",
    "        \n",
    "    return pd.concat(options_list, axis = 0)\n",
    "# ts.get_daily('AAPL')[0].tail(1)['close'][0]\n",
    "'''\n",
    "Function for getting all relevant earnings for a given starting week (Monday in dt.datetime(YYYY, m, d) format)\n",
    "Returns a dataframe with the earnings names, implied move, price, and earnings times.\n",
    "'''\n",
    "def weekly_earnings_check(start_datetime, days_forward):\n",
    "\n",
    "    start_date = start_datetime\n",
    "\n",
    "    weekly_earnings = []\n",
    "    while start_date.weekday() < days_forward:\n",
    "        try:\n",
    "            temp_earnings = yahoo_earnings(start_date)\n",
    "            temp_earnings['Earnings Date'] = start_date\n",
    "            temp_earnings['Last Close'] = 0\n",
    "            for idx, row in temp_earnings.iterrows():\n",
    "                temp_earnings.loc[idx, 'Last Close'] = ts.get_daily(row['Tickers'])[0].tail(1)['close'][0]\n",
    "            weekly_earnings.append(temp_earnings)\n",
    "            start_date = start_date + dt.timedelta(1)\n",
    "        except:\n",
    "            start_date = start_date + dt.timedelta(1)\n",
    "\n",
    "    earnings_df = pd.concat(weekly_earnings,axis = 0, ignore_index = True)\n",
    "    earnings_df = earnings_df[earnings_df['Last Close'] >= 30]\n",
    "    earnings_df['Implied Move Weekly'] = pd.to_numeric(earnings_df['Implied Move Weekly'])\n",
    "    #earnings_df = earnings_df[earnings_df['Call Times'] != '-']\n",
    "    earnings_df['Lower Bound'] = np.round(earnings_df['Last Close']*(1 - earnings_df['Implied Move Weekly']/100),2)\n",
    "    earnings_df = earnings_df.sort_values(['Earnings Date','Call Times'])\n",
    "    \n",
    "    return earnings_df\n",
    "\n",
    "def stock_earnings(tick):\n",
    "    yahoo_url = 'https://finance.yahoo.com/calendar/earnings/?symbol={0}'.format(tick)\n",
    "    res = requests.get(yahoo_url).text\n",
    "    res = res.split('table class')[1].split('</table>')[0].split('<tbody data-reactid=\"')[1].split('<td class=\"')\n",
    "    earnings_cols = list(filter(lambda x: 'data-col2' in x, res))\n",
    "    estimate_cols = list(filter(lambda x: 'data-col3' in x, res))\n",
    "    reported_cols = list(filter(lambda x: 'data-col4' in x, res))\n",
    "\n",
    "    earnings_days = []\n",
    "    for i in earnings_cols:\n",
    "        temp_date = i.split('\">')[2].split('</')[0]\n",
    "        temp_date = ''.join(temp_date.split(',')[:-1])\n",
    "        temp_date = dt.datetime.strptime(temp_date, '%b %d %Y')\n",
    "        earnings_days.append(temp_date)\n",
    "\n",
    "    estimate_eps = []\n",
    "    for i in estimate_cols:\n",
    "        try:\n",
    "            temp_est = float(i.split('\">')[1].split('<')[0])\n",
    "        except:\n",
    "            temp_est = np.nan\n",
    "        estimate_eps.append(temp_est)\n",
    "\n",
    "    reported_eps = []\n",
    "    for i in reported_cols:\n",
    "        try:\n",
    "            temp_est = float(i.split('\">')[1].split('<')[0])\n",
    "        except:\n",
    "            temp_est = np.nan\n",
    "        reported_eps.append(temp_est)\n",
    "\n",
    "    earnings = pd.DataFrame({'Earnings Dates': earnings_days,\n",
    "                             'EPS Estimate': estimate_eps,\n",
    "                             'EPS Reported': reported_eps})\n",
    "    return earnings\n",
    "\n",
    "def old_weekly_earnings_check(start_datetime, days_forward):\n",
    "    \n",
    "    def yahoo_earnings_raw(raw_html_table):\n",
    "        tickers = []\n",
    "        eps = []\n",
    "        i = 1\n",
    "        end_row = 10\n",
    "        for row in raw_html_table.find_all('tr'):\n",
    "            # Individual row stores current row item and delimits on '\\n'\n",
    "            individual_row = str(row).split('\\n')\n",
    "            row_items = individual_row[0].split('</span>')[:3]\n",
    "\n",
    "            if i == 1:\n",
    "                i += 1\n",
    "                continue\n",
    "            tick = row_items[0].split('data-symbol=\"')[1].split('\"')[0]\n",
    "            tickers.append(tick)\n",
    "\n",
    "\n",
    "        return pd.DataFrame({'Tickers': tickers})\n",
    "    \n",
    "    def yahoo_earnings_old(date):\n",
    "        # Yahoo Earnings Calendar Check\n",
    "\n",
    "        today = date.strftime('%Y-%m-%d')\n",
    "        tables = []\n",
    "        for i in range(6):\n",
    "            yahoo_url = 'https://finance.yahoo.com/calendar/earnings?day=' + today + '&offset={}&size=100'.format(int(i*100))\n",
    "            res = requests.get(yahoo_url)\n",
    "            soup = bs(requests.get(yahoo_url).text, \"lxml\")\n",
    "\n",
    "            try:\n",
    "                table = soup.find_all('table')[0]\n",
    "                tables.append(yahoo_earnings_raw(table))\n",
    "            except:\n",
    "                print('No Table')\n",
    "\n",
    "        return pd.concat(tables,axis = 0, ignore_index = True)\n",
    "    \n",
    "    start_date = start_datetime\n",
    "\n",
    "    weekly_earnings = []\n",
    "    while start_date.weekday() < days_forward:\n",
    "        try: \n",
    "            temp_earnings = yahoo_earnings_old(start_date)\n",
    "            temp_earnings['Earnings Date'] = start_date\n",
    "            weekly_earnings.append(temp_earnings)\n",
    "            start_date = start_date + dt.timedelta(1)\n",
    "        except:\n",
    "            start_date = start_date + dt.timedelta(1)\n",
    "            continue\n",
    "\n",
    "    earnings_df = pd.concat(weekly_earnings,axis = 0, ignore_index = True)\n",
    "    #earnings_df = earnings_df[earnings_df['Call Times'] != '-']\n",
    "    \n",
    "    return earnings_df\n",
    "\n",
    "    \n",
    "def fundamentals(ticker):\n",
    "    \n",
    "    site = 'https://finance.yahoo.com/quote/{0}?p={0}'.format(ticker)\n",
    "\n",
    "    res = requests.get(site)\n",
    "    soup = bs(res.text, 'lxml')\n",
    "    table = soup.find_all('table')[1]\n",
    "    sum_dict = {}\n",
    "\n",
    "    # Looping through the soup lxml text table format\n",
    "    # and splitting each row as a individual string\n",
    "    # and parsing string to retrieve the date,\n",
    "    # open, and close information.\n",
    "\n",
    "\n",
    "    for row in table.find_all('tr'):\n",
    "        # Individual row stores current row item and delimits on '\\n'\n",
    "        individual_row = str(row).split('\\n')[0]\n",
    "\n",
    "        # row_items is parsed string for each current row where each\n",
    "        # item in list is the date, open, high, low, close, and volume\n",
    "        row_items = individual_row.split('<span data-reactid=')[1].split('\"><!-- react-text: ')\n",
    "        \n",
    "        if len(row_items) > 1:\n",
    "            sum_item = row_items[0].split('>')[1].split('<')[0]\n",
    "            sum_value = row_items[1].split('-->')[1].split('<')[0]\n",
    "        elif 'YIELD' in row_items[0]:\n",
    "            try:\n",
    "                temp_val = row_items[0].split('-value\">')[1].split(\"</td>\")[0]\n",
    "                div_amount = float(temp_val.split(' ')[0])\n",
    "                div_yield = float(temp_val.split(' ')[1].replace('(','').replace(')','').replace('%',''))\n",
    "\n",
    "                sum_dict['Div'] = div_amount\n",
    "                sum_dict['Yield'] = div_yield\n",
    "            except:\n",
    "                sum_dict['Div'] = np.nan\n",
    "                sum_dict['Yield'] = np.nan\n",
    "        elif 'Market Cap' in row_items[0]:\n",
    "            sum_item = 'Market Cap (B)'\n",
    "            mkt_cap = row_items[0].split('data-reactid=\"')[-1].split('>')[1].split('<')[0]\n",
    "            mkt_cap_amount = float(mkt_cap[:-1])\n",
    "            if mkt_cap[-1] == 'M':\n",
    "                sum_value = mkt_cap_amount/1000\n",
    "            else:\n",
    "                sum_value = mkt_cap_amount\n",
    "        else:\n",
    "            sum_item = row_items[0].split('>')[1].split('<')[0]\n",
    "            sum_value = row_items[0].split('data-reactid=\"')[-1].split('>')[1].split('<')[0]\n",
    "        \n",
    "        sum_dict[sum_item] = sum_value\n",
    "    \n",
    "    sum_dict['Days Since Last Earnings'] = (dt.datetime.today().date() - \n",
    "                                            stock_earnings(ticker)['Earnings Dates'][1].date()).days\n",
    "\n",
    "    return pd.DataFrame(sum_dict, index = [ticker])\n",
    "\n",
    "# Truncated version of fundamental data\n",
    "def fundamentals_truncated(tick):\n",
    "    data = round(qd.get_table('ZACKS/MKTV', ticker = tick).head(1)[['mkt_val']]/1000,2)\n",
    "    data.columns = ['Market Cap (B)']\n",
    "    data['Days Since Last Earnings'] = (dt.datetime.today().date() - \n",
    "                                        stock_earnings(tick)['Earnings Dates'][1].date()).days\n",
    "    data.index = [tick]\n",
    "    return data\n",
    "\n",
    "# Function to return fundametal data of a ticker list\n",
    "def get_fundas(ticker_lst):\n",
    "    fund_lst = []\n",
    "    for tick in ticker_lst:\n",
    "        try:\n",
    "            fund_lst.append(fundamentals_truncated(tick))\n",
    "        except:\n",
    "            continue\n",
    "    return pd.concat(fund_lst,axis = 0)\n",
    "\n",
    "# Function historical data from alpha advantage\n",
    "def historical_data(ticker, day_number = 252, rolling_window = 20, outsize = 'full'):\n",
    "    alphavantage_link = 'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol={0}&apikey=5HZEUI5AFJB06BUK&datatype=csv&outputsize={1}'.format(ticker, outsize)\n",
    "    stockframe = pd.read_csv(alphavantage_link, index_col = 0).sort_index()[['open', 'close']]\n",
    "    stockframe['daily_ret'] = np.log(stockframe['close']/stockframe['close'].shift(1))\n",
    "    stockframe['intra_ret'] = np.log(stockframe['close']/stockframe['open'])\n",
    "    stockframe['ovrnt_ret'] = np.log(stockframe['open']/stockframe['close'].shift(1))\n",
    "    stockframe['daily_vol'] = stockframe.daily_ret.rolling(window=rolling_window,center=False).std()\n",
    "    stockframe['intra_vol'] = stockframe.intra_ret.rolling(window=rolling_window,center=False).std()\n",
    "    stockframe['ovrnt_vol'] = stockframe.ovrnt_ret.rolling(window=rolling_window,center=False).std()\n",
    "    stockframe['daily_ann'] = stockframe.daily_vol*np.sqrt(252)\n",
    "    stockframe['intra_ann'] = stockframe.intra_vol*np.sqrt((24/6.5)*252)\n",
    "    stockframe['ovrnt_ann'] = stockframe.ovrnt_vol*np.sqrt((24/17.5)*252)\n",
    "    stockframe['oc_diff'] = stockframe.close - stockframe.open\n",
    "    stockframe['daily_dollar_vol'] = stockframe.daily_vol*stockframe.close.shift(1)\n",
    "    stockframe['daily_dollar_std'] = np.abs(stockframe.oc_diff/stockframe.daily_dollar_vol)\n",
    "\n",
    "    return stockframe.tail(day_number)\n",
    "\n",
    "# Function for building a dataframe of volatilities\n",
    "# Daily, Intraday, Overnight\n",
    "def current_volatility(ticker_list, roll = 20):\n",
    "    \n",
    "    rows = []\n",
    "    failed_tickers = []\n",
    "    \n",
    "    def failed_check(failed_lst,rows):\n",
    "        if len(failed_lst) == 0:\n",
    "            return failed_lst, rows\n",
    "        else:\n",
    "            new_lst = []\n",
    "            new_rows = rows\n",
    "            for tick in failed_lst:\n",
    "                try: \n",
    "                    curr_vol = historical_data(tick, outsize = 'compact').tail(1)[['daily_ann','intra_ann','ovrnt_ann','close',\n",
    "                                                                                   'daily_dollar_vol']]\n",
    "                    curr_vol.index.name = 'Tickers'\n",
    "                    curr_vol.index = [tick]\n",
    "                    new_rows.append(curr_vol)\n",
    "                except:\n",
    "                    new_lst.append(tick)\n",
    "            return failed_check(new_lst, rows)\n",
    "\n",
    "    for tick in ticker_list:\n",
    "        try: \n",
    "            curr_vol = historical_data(tick, outsize = 'compact').tail(1)[['daily_ann','intra_ann','ovrnt_ann','close',\n",
    "                                                                           'daily_dollar_vol']]\n",
    "            curr_vol.index.name = 'Tickers'\n",
    "            curr_vol.index = [tick]\n",
    "            rows.append(curr_vol)\n",
    "        except:\n",
    "            failed_tickers.append(tick)\n",
    "            \n",
    "    failed_lst, rows = failed_check(failed_tickers, rows)\n",
    "        \n",
    "    return pd.concat(rows, axis = 0)\n",
    "\n",
    "# Function for pulling S&P500 data and calculating volatilities\n",
    "def sp500_filter():\n",
    "    sp500 = pull_sp500_list()\n",
    "    sp500_vols = current_volatility(sp500.index.tolist())\n",
    "    df = pd.concat([sp500_vols, sp500], axis = 1).dropna()\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_raw_data(ticker):\n",
    "    tape = Options(ticker, 'yahoo')\n",
    "    data = tape.get_all_data()\n",
    "    return data\n",
    "\n",
    "# Function for pulling options for a given ticker\n",
    "def option_filter(ticker, moneyness_thresh, dte_thresh):\n",
    "    fwd_date = dt.datetime.today() + dt.timedelta(days = dte_thresh)\n",
    "    tape = Options(ticker, 'yahoo')\n",
    "    data = tape.get_options_data(month = fwd_date.month, year = fwd_date.year).reset_index()\n",
    "    data['Moneyness'] = np.abs(data['Strike'] - data['Underlying_Price'])/data['Underlying_Price']\n",
    "    \n",
    "    data['DTE'] = (data['Expiry'] - dt.datetime.today()).dt.days\n",
    "    data = data[['Strike', 'DTE', 'Type', 'IV', 'Vol','Open_Int', 'Moneyness', 'Root', 'Underlying_Price',\n",
    "                 'Last','Bid','Ask']]\n",
    "    data['Mid'] = (data['Ask'] - data['Bid'])/2 + data['Bid']\n",
    "\n",
    "    filtered_data = data[(data['Moneyness'] <= moneyness_thresh) &\n",
    "                         (data['DTE'] <= dte_thresh)].reset_index()[data.columns]\n",
    "    put_ivs = filtered_data[filtered_data.Type == 'put'].pivot(index='Strike', columns='DTE', \n",
    "                                                               values='IV').dropna()\n",
    "    call_ivs = filtered_data[filtered_data.Type == 'put'].pivot(index='Strike', columns='DTE', \n",
    "                                                                values='IV').dropna()\n",
    "    hv_data = current_volatility([ticker])\n",
    "\n",
    "    put_ivs['Close'] = hv_data['close'][0]\n",
    "    call_ivs['Close'] = hv_data['close'][0]\n",
    "    put_ivs['Daily HV'] = hv_data['daily_ann'][0]\n",
    "    call_ivs['Daily HV'] = hv_data['daily_ann'][0]\n",
    "    put_ivs['Intra HV'] = hv_data['intra_ann'][0]\n",
    "    call_ivs['Intra HV'] = hv_data['intra_ann'][0]\n",
    "    put_ivs['Overnight HV'] = hv_data['ovrnt_ann'][0]\n",
    "    call_ivs['Overnight HV'] = hv_data['ovrnt_ann'][0]\n",
    "    put_ivs['Daily Dollar Vol'] = hv_data['daily_dollar_vol'][0]\n",
    "    call_ivs['Daily Dollar Vol'] = hv_data['daily_dollar_vol'][0]\n",
    "    \n",
    "    put_ivs['Moneyness'] = np.abs(put_ivs.index - put_ivs['Close'])/put_ivs['Close']\n",
    "    call_ivs['Moneyness'] = np.abs(call_ivs.index - call_ivs['Close'])/call_ivs['Close']\n",
    "\n",
    "    call_ivs.index.name = ticker + ' Call Strike'\n",
    "    put_ivs.index.name = ticker + ' Put Strike'\n",
    "    return call_ivs, put_ivs\n",
    "\n",
    "def phase1_options_filter(ticker_lst, hv_day_roll, atm_distance, dte_thresh, iv_hv_thresh):\n",
    "    \n",
    "    pulled_options = []\n",
    "    calls = {}\n",
    "    puts = {}\n",
    "\n",
    "    moneyness_thresh = atm_distance\n",
    "\n",
    "    for tick in ticker_lst:\n",
    "        try:\n",
    "            call, put = option_filter(tick, moneyness_thresh, dte_thresh)\n",
    "            \n",
    "            call_check = call.sort_values('Moneyness').head(1)\n",
    "            # Checking IV vs HV of the options chain out more than 2 weeks\n",
    "            iv_chain_to_check = list(filter(lambda x: x >= hv_day_roll, \n",
    "                                            list(filter(lambda x: type(x) == int,call_check.columns.tolist()))))[0]\n",
    "            \n",
    "            average_difference_iv_hv = abs(call_check[iv_chain_to_check] - call_check['Intra HV']).mean()\n",
    "\n",
    "            if average_difference_iv_hv >= iv_hv_thresh:\n",
    "                calls[tick] = call\n",
    "                puts[tick] = put\n",
    "                pulled_options.append(tick)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    return pulled_options, calls, puts\n",
    "\n",
    "def greek_calc(ticker, dte_ub, dte_lb, prem_price_use = 'Mid', delta_filter = 0.2, expiry_set = 0):\n",
    "    options_chain = get_raw_data(ticker).reset_index()\n",
    "    options_chain = options_chain[['Strike','Expiry','Type','Last','Bid','Ask','Vol','Open_Int','IV','Underlying_Price']]\n",
    "    df = options_chain\n",
    "    df['DTE'] = (df['Expiry'] - dt.datetime.today()).dt.days\n",
    "    df['Mid'] = (df['Ask'] + df['Bid'])/2\n",
    "    df = df[(df['DTE'] <= dte_ub) & (df['DTE'] >= dte_lb)]\n",
    "    df = df.reset_index()[df.columns]\n",
    "    \n",
    "    year = 365\n",
    "    premiums = df[prem_price_use].values # 'Last' or 'Mid'\n",
    "    strikes = df['Strike'].values\n",
    "    time_to_expirations = df['DTE'].values\n",
    "    ivs = df['IV'].values\n",
    "    underlying = df['Underlying_Price'].values[0]\n",
    "    types = df['Type'].values\n",
    "\n",
    "    # Make sure nothing thows up\n",
    "    assert len(premiums) == len(strikes)\n",
    "    assert len(strikes) == len(time_to_expirations)\n",
    "\n",
    "    sigmas = []\n",
    "    deltas = []\n",
    "    gammas = []\n",
    "    thetas = []\n",
    "    vegas = []\n",
    "    prices = []\n",
    "    for premium, strike, time_to_expiration, flag in zip(premiums, strikes, time_to_expirations, types):\n",
    "\n",
    "        # Constants\n",
    "        P = premium\n",
    "        S = underlying\n",
    "        K = strike\n",
    "        t = time_to_expiration/float(year)\n",
    "        r = 0.005 / 100\n",
    "        q = 0 / 100\n",
    "        try:\n",
    "            sigma = implied_volatility(P, S, K, t, r, q, flag[0])\n",
    "            sigmas.append(sigma)\n",
    "        except:\n",
    "            sigma = 0.0\n",
    "            sigmas.append(sigma)\n",
    "\n",
    "        try:\n",
    "            delta = py_vollib.black_scholes_merton.greeks.analytical.delta(flag[0], S, K, t, r, sigma, q)\n",
    "            deltas.append(delta)\n",
    "        except:\n",
    "            delta = 0.0\n",
    "            deltas.append(delta)\n",
    "\n",
    "        try:\n",
    "            gamma = py_vollib.black_scholes_merton.greeks.analytical.gamma(flag[0], S, K, t, r, sigma, q)\n",
    "            gammas.append(gamma)\n",
    "        except:\n",
    "            gamma = 0.0\n",
    "            gammas.append(gamma)\n",
    "\n",
    "        try:\n",
    "            theta = py_vollib.black_scholes_merton.greeks.analytical.theta(flag[0], S, K, t, r, sigma, q)\n",
    "            thetas.append(theta)\n",
    "        except:\n",
    "            theta = 0.0\n",
    "            thetas.append(theta)\n",
    "\n",
    "        try:\n",
    "            vega = py_vollib.black_scholes_merton.greeks.analytical.vega(flag[0], S, K, t, r, sigma, q)\n",
    "            vegas.append(vega)\n",
    "        except:\n",
    "            vega = 0.0\n",
    "            vegas.append(vega)\n",
    "\n",
    "    ivs = np.array(sigmas)\n",
    "    df['Calc IV'] = ivs\n",
    "    df['Delta'] = deltas\n",
    "    df['Gamma'] = gammas\n",
    "    df['Theta'] = thetas\n",
    "    df['Vega'] = vegas\n",
    "    df = df.dropna()\n",
    "\n",
    "    expiry_filter = df.sort_values('DTE')['DTE'].drop_duplicates().values[min(expiry_set, \n",
    "                                                                              len(df.sort_values('DTE')['DTE'].drop_duplicates()))]\n",
    "\n",
    "    calls = df[(abs(df['Delta']) >= delta_filter) & \n",
    "               (df['Type'] == 'call') & \n",
    "               (df['DTE'] == expiry_filter)].reset_index()[df.columns]\n",
    "    puts = df[(abs(df['Delta']) >= delta_filter) & \n",
    "              (df['Type'] == 'put') & \n",
    "              (df['DTE'] == expiry_filter)].reset_index()[df.columns]\n",
    "    \n",
    "    return calls, puts\n",
    "\n",
    "def price_sim(options_df, price_change, vol_change, days_change, iv_tag = 'Calc IV', output = 'All'):\n",
    "    '''\n",
    "    output types can be: All, Price, Delta, Gamma, Vega, Theta\n",
    "    '''\n",
    "    year = 365\n",
    "    strikes = options_df['Strike'].values\n",
    "    time_to_expirations = options_df['DTE'].values\n",
    "    ivs = options_df[iv_tag].values\n",
    "    underlying = options_df['Underlying_Price'].values[0]\n",
    "    types = options_df['Type'].values\n",
    "\n",
    "    # Tweaking changes\n",
    "    prices = []\n",
    "    deltas = []\n",
    "    gammas = []\n",
    "    thetas = []\n",
    "    vegas = []\n",
    "    for sigma, strike, time_to_expiration, flag in zip(ivs, strikes, time_to_expirations, types):\n",
    "\n",
    "        # Constants\n",
    "        S = underlying*(1 + price_change)\n",
    "        t = max(time_to_expiration - days_change, 0)/float(year)\n",
    "        sigma = sigma + vol_change\n",
    "        K = strike\n",
    "        r = 0.005 / 100\n",
    "        q = 0 / 100\n",
    "        \n",
    "        if (output == 'All') or (output == 'Price'):\n",
    "            if days_change == time_to_expiration:\n",
    "                if flag == 'call':\n",
    "                    price = max(S - K, 0.0)\n",
    "                else:\n",
    "                    price = max(K - S, 0.0)\n",
    "                prices.append(price)\n",
    "            else:\n",
    "                try:\n",
    "                    price = py_vollib.black_scholes_merton.black_scholes_merton(flag[0], S, K, t, r, sigma, q)\n",
    "                    prices.append(price)\n",
    "                except:\n",
    "                    price = 0.0\n",
    "                    prices.append(price)\n",
    "                    \n",
    "        if (output == 'All') or (output == 'Delta'):\n",
    "            try:\n",
    "                delta = py_vollib.black_scholes_merton.greeks.analytical.delta(flag[0], S, K, t, r, sigma, q)\n",
    "                deltas.append(delta)\n",
    "            except:\n",
    "                delta = 0.0\n",
    "                deltas.append(delta)\n",
    "        \n",
    "        if (output == 'All') or (output == 'Gamma'):\n",
    "            try:\n",
    "                gamma = py_vollib.black_scholes_merton.greeks.analytical.gamma(flag[0], S, K, t, r, sigma, q)\n",
    "                gammas.append(gamma)\n",
    "            except:\n",
    "                gamma = 0.0\n",
    "                gammas.append(gamma)\n",
    "            \n",
    "        if (output == 'All') or (output == 'Theta'):\n",
    "            try:\n",
    "                theta = py_vollib.black_scholes_merton.greeks.analytical.theta(flag[0], S, K, t, r, sigma, q)\n",
    "                thetas.append(theta)\n",
    "            except:\n",
    "                theta = 0.0\n",
    "                thetas.append(theta)\n",
    "        \n",
    "        if (output == 'All') or (output == 'Vega'):\n",
    "            try:\n",
    "                vega = py_vollib.black_scholes_merton.greeks.analytical.vega(flag[0], S, K, t, r, sigma, q)\n",
    "                vegas.append(vega)\n",
    "            except:\n",
    "                vega = 0.0\n",
    "                vegas.append(vega)\n",
    "            \n",
    "    df = options_df[['Strike','Expiry','DTE','Type','Last','Bid','Ask','Mid','Underlying_Price']]\n",
    "    if (output == 'All') or (output == 'Price'):\n",
    "        df['Simulated Price'] = prices\n",
    "        df['Price Change'] = df['Simulated Price']/df['Mid'] - 1\n",
    "    if (output == 'All') or (output == 'Delta'):\n",
    "        df['Delta'] = deltas\n",
    "    if (output == 'All') or (output == 'Gamma'):\n",
    "        df['Gamma'] = gammas\n",
    "    if (output == 'All') or (output == 'Theta'):\n",
    "        df['Theta'] = thetas\n",
    "    if (output == 'All') or (output == 'Vega'):\n",
    "        df['Vega'] = vegas\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "def position_sim(position_df, holdings, price_change, vol_change, dte_change, iv_tag = 'Calc IV', output = 'All'):\n",
    "    position = position_df\n",
    "    position['Cost'] = position['Mid']\n",
    "    position['Pos'] = holdings\n",
    "    position_dict = {}\n",
    "    position_dict['Total Cost'] = sum(position['Cost']*position['Pos'])\n",
    "    position_dict['Original Delta'] = sum(position['Delta']*position['Pos'])\n",
    "    position_dict['Original Gamma'] = sum(position['Gamma']*position['Pos'])\n",
    "    position_dict['Original Theta'] = sum(position['Theta']*position['Pos'])\n",
    "    position_dict['Original Vega'] = sum(position['Vega']*position['Pos'])\n",
    "    \n",
    "    if (output == 'PnL') or (output == 'Percent Return'):\n",
    "        simulation = price_sim(position, price_change, vol_change, dte_change, iv_tag, 'Price')\n",
    "    else:\n",
    "        simulation = price_sim(position, price_change, vol_change, dte_change, iv_tag, output)\n",
    "    \n",
    "    if (output == 'All') or (output == 'PnL') or (output == 'Percent Return'):\n",
    "        position_dict['Simulated Price'] = sum(simulation['Simulated Price']*position['Pos'])\n",
    "        position_dict['PnL'] = sum(simulation['Simulated Price']*position['Pos']) - position_dict['Total Cost']\n",
    "        if position_dict['Total Cost'] > 0:\n",
    "            position_dict['Percent Return'] = position_dict['PnL']/position_dict['Total Cost']\n",
    "        else:\n",
    "            position_dict['Percent Return'] = -position_dict['PnL']/position_dict['Total Cost']\n",
    "            \n",
    "    if (output == 'All') or (output == 'Delta'):\n",
    "        position_dict['Simulated Delta'] = sum(simulation['Delta']*position['Pos'])\n",
    "        \n",
    "    if (output == 'All') or (output == 'Gamma'):\n",
    "        position_dict['Simulated Gamma'] = sum(simulation['Gamma']*position['Pos'])\n",
    "        \n",
    "    if (output == 'All') or (output == 'Theta'):\n",
    "        position_dict['Simulated Theta'] = sum(simulation['Theta']*position['Pos'])\n",
    "        \n",
    "    if (output == 'All') or (output == 'Vega'):\n",
    "        position_dict['Simulated Vega'] = sum(simulation['Vega']*position['Pos'])\n",
    "    \n",
    "    outframe = pd.DataFrame(position_dict, index = [vol_change])\n",
    "    return outframe\n",
    "\n",
    "def all_options(ticker):\n",
    "    tape = Options(ticker, 'yahoo')\n",
    "    data = tape.get_all_data().reset_index()\n",
    "    \n",
    "    data['Moneyness'] = np.abs(data['Strike'] - data['Underlying_Price'])/data['Underlying_Price']\n",
    "    \n",
    "    data['DTE'] = (data['Expiry'] - dt.datetime.today()).dt.days\n",
    "    data = data[['Strike', 'DTE', 'Type', 'IV', 'Vol','Open_Int', 'Moneyness', 'Root', 'Underlying_Price',\n",
    "                 'Last','Bid','Ask']]\n",
    "    data['Mid'] = (data['Ask'] - data['Bid'])/2 + data['Bid']\n",
    "    \n",
    "    year = 365\n",
    "    strikes = data['Strike'].values\n",
    "    time_to_expirations = data['DTE'].values\n",
    "    ivs = data['IV'].values\n",
    "    underlying = data['Underlying_Price'].values[0]\n",
    "    types = data['Type'].values\n",
    "\n",
    "    # Make sure nothing thows up\n",
    "    assert len(strikes) == len(time_to_expirations)\n",
    "\n",
    "    sigmas = data['IV']\n",
    "    deltas = []\n",
    "    gammas = []\n",
    "    thetas = []\n",
    "    vegas = []\n",
    "    for sigma, strike, time_to_expiration, flag in zip(sigmas, strikes, time_to_expirations, types):\n",
    "\n",
    "        # Constants\n",
    "        S = underlying\n",
    "        K = strike\n",
    "        t = time_to_expiration/float(year)\n",
    "        r = 0.005 / 100\n",
    "        q = 0 / 100\n",
    "\n",
    "        try:\n",
    "            delta = py_vollib.black_scholes_merton.greeks.analytical.delta(flag[0], S, K, t, r, sigma, q)\n",
    "            deltas.append(delta)\n",
    "        except:\n",
    "            delta = 0.0\n",
    "            deltas.append(delta)\n",
    "\n",
    "        try:\n",
    "            gamma = py_vollib.black_scholes_merton.greeks.analytical.gamma(flag[0], S, K, t, r, sigma, q)\n",
    "            gammas.append(gamma)\n",
    "        except:\n",
    "            gamma = 0.0\n",
    "            gammas.append(gamma)\n",
    "\n",
    "        try:\n",
    "            theta = py_vollib.black_scholes_merton.greeks.analytical.theta(flag[0], S, K, t, r, sigma, q)\n",
    "            thetas.append(theta)\n",
    "        except:\n",
    "            theta = 0.0\n",
    "            thetas.append(theta)\n",
    "\n",
    "        try:\n",
    "            vega = py_vollib.black_scholes_merton.greeks.analytical.vega(flag[0], S, K, t, r, sigma, q)\n",
    "            vegas.append(vega)\n",
    "        except:\n",
    "            vega = 0.0\n",
    "            vegas.append(vega)\n",
    "\n",
    "    data['Delta'] = deltas\n",
    "    data['Gamma'] = gammas\n",
    "    data['Theta'] = thetas\n",
    "    data['Vega'] = vegas\n",
    "\n",
    "    return data.dropna().reset_index()[data.columns]\n",
    "\n",
    "def combo_check(df, dte_spec, type_spec, short_pos = 1, long_pos = 2, order_style = 'market'):\n",
    "    opt_df = df[(df['DTE'] == dte_spec) & \n",
    "                (df['Type'] == type_spec) &\n",
    "                (abs(df['Delta']) <= 0.5)].reset_index()[df.columns]\n",
    "\n",
    "    short_strike = []\n",
    "    long_strike = []\n",
    "    net_credit = []\n",
    "    max_loss = []\n",
    "    pos_delta = []\n",
    "    pos_theta = []\n",
    "    pos_gamma = []\n",
    "    pos_vega = []\n",
    "    short_bids =[]\n",
    "    short_asks = []\n",
    "    long_bids = []\n",
    "    long_asks = []\n",
    "\n",
    "    for i, low_strike_col in opt_df.iterrows():\n",
    "        if i == (len(opt_df) - 1):\n",
    "            break\n",
    "        else:\n",
    "            for j, high_strike_col in opt_df.iloc[i:,].iterrows():\n",
    "                if low_strike_col.Type == 'call':\n",
    "                    curr_short = low_strike_col\n",
    "                    curr_long = high_strike_col\n",
    "                else:\n",
    "                    curr_short = high_strike_col\n",
    "                    curr_long = low_strike_col\n",
    "                \n",
    "                curr_max_loss = curr_long.Strike - curr_short.Strike\n",
    "\n",
    "                if order_style == 'market':\n",
    "                    curr_credit = short_pos*curr_short.Bid - long_pos*curr_long.Ask\n",
    "                elif order_style == 'mid':\n",
    "                    curr_credit == short_pos*curr_short.Mid - long_pos*curr_long.Mid\n",
    "                else:\n",
    "                    curr_credit == short_pos*curr_short.Last - long_pos*curr_long.Last\n",
    "\n",
    "                if curr_credit >= 0:\n",
    "                    short_strike.append(curr_short.Strike)\n",
    "                    long_strike.append(curr_long.Strike)\n",
    "                    pos_delta.append(long_pos*curr_long.Delta - short_pos*curr_short.Delta)\n",
    "                    pos_theta.append(long_pos*curr_long.Theta - short_pos*curr_short.Theta)\n",
    "                    pos_gamma.append(long_pos*curr_long.Gamma - short_pos*curr_short.Gamma)\n",
    "                    pos_vega.append(long_pos*curr_long.Vega - short_pos*curr_short.Vega)\n",
    "                    net_credit.append(curr_credit)\n",
    "                    max_loss.append(curr_max_loss + curr_credit)\n",
    "                    short_bids.append(curr_short.Bid)\n",
    "                    short_asks.append(curr_short.Ask)\n",
    "                    long_bids.append(curr_long.Bid)\n",
    "                    long_asks.append(curr_long.Ask)\n",
    "\n",
    "    comb_df = pd.DataFrame({'Short Strike': short_strike, 'Long Strike': long_strike,\n",
    "                            'Net Credit': net_credit, 'Max Loss': max_loss, 'Delta': pos_delta,\n",
    "                            'Theta': pos_theta, 'Gamma': pos_gamma, 'Vega': pos_vega,\n",
    "                            'Short Bid': short_bids, 'Short Ask': short_asks, \n",
    "                            'Long Bid': long_bids, 'Long Ask': long_asks},\n",
    "                           index = range(len(net_credit)))\n",
    "    comb_df['DTE'] = dte_spec\n",
    "    comb_df['Type'] = type_spec\n",
    "    return comb_df.reset_index()[comb_df.columns]\n",
    "\n",
    "def combo_scanner(df, short_pos, long_pos, order_style, theta_thresh, delta_thresh,\n",
    "                  dte_lb, dte_ub):\n",
    "\n",
    "    dtes = df.DTE.drop_duplicates().values\n",
    "    types = ['call','put']\n",
    "    short_pos = 1\n",
    "    long_pos = 2\n",
    "    order_style = 'market'\n",
    "\n",
    "    all_combos = []\n",
    "    for type_spec in types:\n",
    "        for dte_spec in dtes:\n",
    "            all_combos.append(combo_check(df, dte_spec, type_spec, short_pos = 1, long_pos = 2, order_style = 'market'))\n",
    "\n",
    "    all_combo_df = pd.concat(all_combos, axis = 0)\n",
    "    return all_combo_df[(all_combo_df['DTE'] >= dte_lb) &\n",
    "                        (all_combo_df['DTE'] <= dte_ub) &\n",
    "                        (all_combo_df['Theta'] >= theta_thresh) &\n",
    "                        (abs(all_combo_df['Delta']) <= delta_thresh)].sort_values(['Max Loss'],\n",
    "                                                                                  ascending = False).reset_index()[all_combo_df.columns]\n",
    "\n",
    "def back_ratio_opt(ticker_lst, max_rows, short_pos, long_pos, order_style, theta_thresh, delta_thresh,\n",
    "                   dte_lb, dte_ub):\n",
    "    \n",
    "    combo_lst = []\n",
    "    failed_names = []\n",
    "    for ticker in ticker_lst:\n",
    "        try: \n",
    "            curr_df = combo_scanner(all_options(ticker), short_pos, long_pos, order_style, theta_thresh, \n",
    "                                    delta_thresh, dte_lb, dte_ub).head(max_rows)\n",
    "            curr_df['Ticker'] = ticker\n",
    "            combo_lst.append(curr_df)\n",
    "        except:\n",
    "            failed_names.append(ticker)\n",
    "    \n",
    "    out_df = pd.concat(combo_lst, axis = 0)\n",
    "    \n",
    "    return out_df.sort_values(['Max Loss'], ascending = False).reset_index()[out_df.columns]\n",
    "\n",
    "def earnings_condor(tick, max_gap, dte_thresh, money_thresh):\n",
    "    chain = all_options(tick)\n",
    "    chain = chain[chain['DTE'] <= dte_thresh]\n",
    "    chain = chain.reset_index()[chain.columns]\n",
    "    chain = chain[chain['Moneyness'] <= money_thresh]\n",
    "    chain_puts = chain[(chain['Type'] == 'put') & (chain['Strike'] < chain['Underlying_Price'].values[0])]\n",
    "    chain_calls = chain[(chain['Type'] == 'call') & (chain['Strike'] > chain['Underlying_Price'].values[0])]\n",
    "\n",
    "\n",
    "    put_spread_prem = []\n",
    "    put_spread_delta = []\n",
    "    put_spread_gamma = []\n",
    "    put_spread_vega = []\n",
    "    put_spread_theta = []\n",
    "    put_spread_short_strike = []\n",
    "    put_spread_long_strike = []\n",
    "    put_spread_max_loss = []\n",
    "    for idx, row in chain_puts.sort_values('Strike', ascending = False).iterrows():\n",
    "        curr_short_strike = row.Strike\n",
    "        curr_short_prem = row.Bid\n",
    "        curr_short_delta = row.Delta\n",
    "        curr_short_gamma = row.Gamma\n",
    "        curr_short_vega = row.Vega\n",
    "        curr_short_theta = row.Theta\n",
    "\n",
    "        temp_longs = chain_puts[(chain_puts['Strike'] < curr_short_strike) &\n",
    "                                (chain_puts['Strike'] >= curr_short_strike - max_gap)]\n",
    "\n",
    "        for temp_idx, temp_row in temp_longs.iterrows():\n",
    "            curr_long_strike = temp_row.Strike\n",
    "            curr_long_prem = temp_row.Ask\n",
    "            curr_long_delta = temp_row.Delta\n",
    "            curr_long_gamma = temp_row.Gamma\n",
    "            curr_long_vega = temp_row.Vega\n",
    "            curr_long_theta = temp_row.Theta\n",
    "\n",
    "            curr_spread_prem = curr_short_prem - curr_long_prem\n",
    "            curr_spread_delta = -curr_short_delta + curr_long_delta\n",
    "            curr_spread_gamma = -curr_short_gamma + curr_long_gamma\n",
    "            curr_spread_vega = -curr_short_vega + curr_long_vega\n",
    "            curr_spread_theta = -curr_short_theta + curr_long_theta\n",
    "            curr_spread_maxloss = (curr_short_strike - curr_long_strike - curr_spread_prem)*100\n",
    "\n",
    "            put_spread_prem.append(curr_spread_prem)\n",
    "            put_spread_delta.append(curr_spread_delta)\n",
    "            put_spread_gamma.append(curr_spread_gamma)\n",
    "            put_spread_vega.append(curr_spread_vega)\n",
    "            put_spread_theta.append(curr_spread_theta)\n",
    "            put_spread_short_strike.append(curr_short_strike)\n",
    "            put_spread_long_strike.append(curr_long_strike)\n",
    "            put_spread_max_loss.append(curr_spread_maxloss)\n",
    "\n",
    "    put_spreads_df = pd.DataFrame(OrderedDict({'put Combo': range(len(put_spread_prem)),\n",
    "                                               'Short Put Strike': put_spread_short_strike,\n",
    "                                               'Long Put Strike': put_spread_long_strike,\n",
    "                                               'put Spread Premium': put_spread_prem,\n",
    "                                               'put Spread Maxloss': put_spread_max_loss,\n",
    "                                               'put Spread Delta': put_spread_delta,\n",
    "                                               'put Spread Gamma': put_spread_gamma,\n",
    "                                               'put Spread Vega': put_spread_vega,\n",
    "                                               'put Spread Theta': put_spread_theta}),\n",
    "                                  index = range(len(put_spread_prem)))\n",
    "\n",
    "    call_spread_prem = []\n",
    "    call_spread_delta = []\n",
    "    call_spread_gamma = []\n",
    "    call_spread_vega = []\n",
    "    call_spread_theta = []\n",
    "    call_spread_short_strike = []\n",
    "    call_spread_long_strike = []\n",
    "    call_spread_max_loss = []\n",
    "    for idx, row in chain_calls.sort_values('Strike', ascending = True).iterrows():\n",
    "        curr_short_strike = row.Strike\n",
    "        curr_short_prem = row.Bid\n",
    "        curr_short_delta = row.Delta\n",
    "        curr_short_gamma = row.Gamma\n",
    "        curr_short_vega = row.Vega\n",
    "        curr_short_theta = row.Theta\n",
    "\n",
    "        temp_longs = chain_calls[(chain_calls['Strike'] > curr_short_strike) &\n",
    "                                (chain_calls['Strike'] <= curr_short_strike + max_gap)]\n",
    "\n",
    "        for temp_idx, temp_row in temp_longs.iterrows():\n",
    "            curr_long_strike = temp_row.Strike\n",
    "            curr_long_prem = temp_row.Ask\n",
    "            curr_long_delta = temp_row.Delta\n",
    "            curr_long_gamma = temp_row.Gamma\n",
    "            curr_long_vega = temp_row.Vega\n",
    "            curr_long_theta = temp_row.Theta\n",
    "\n",
    "            curr_spread_prem = curr_short_prem - curr_long_prem\n",
    "            curr_spread_delta = -curr_short_delta + curr_long_delta\n",
    "            curr_spread_gamma = -curr_short_gamma + curr_long_gamma\n",
    "            curr_spread_vega = -curr_short_vega + curr_long_vega\n",
    "            curr_spread_theta = -curr_short_theta + curr_long_theta\n",
    "            curr_spread_maxloss = -(curr_short_strike - curr_long_strike + curr_spread_prem)*100\n",
    "\n",
    "            call_spread_prem.append(curr_spread_prem)\n",
    "            call_spread_delta.append(curr_spread_delta)\n",
    "            call_spread_gamma.append(curr_spread_gamma)\n",
    "            call_spread_vega.append(curr_spread_vega)\n",
    "            call_spread_theta.append(curr_spread_theta)\n",
    "            call_spread_short_strike.append(curr_short_strike)\n",
    "            call_spread_long_strike.append(curr_long_strike)\n",
    "            call_spread_max_loss.append(curr_spread_maxloss)\n",
    "\n",
    "    call_spreads_df = pd.DataFrame(OrderedDict({'call Combo': range(len(call_spread_prem)),\n",
    "                                               'Short call Strike': call_spread_short_strike,\n",
    "                                               'Long call Strike': call_spread_long_strike,\n",
    "                                               'call Spread Premium': call_spread_prem,\n",
    "                                               'call Spread Maxloss': call_spread_max_loss,\n",
    "                                               'call Spread Delta': call_spread_delta,\n",
    "                                               'call Spread Gamma': call_spread_gamma,\n",
    "                                               'call Spread Vega': call_spread_vega,\n",
    "                                               'call Spread Theta': call_spread_theta}),\n",
    "                                  index = range(len(call_spread_prem)))\n",
    "\n",
    "    put_combos = []\n",
    "    call_combos = []\n",
    "    condor_prems = []\n",
    "    condor_maxloss = []\n",
    "    condor_delta = []\n",
    "    condor_gamma = []\n",
    "    condor_vega = []\n",
    "    condor_theta = []\n",
    "    put_short = []\n",
    "    put_long = []\n",
    "    call_short = []\n",
    "    call_long = []\n",
    "\n",
    "    for idxc, rowc in call_spreads_df.iterrows():\n",
    "        for idxp, rowp in put_spreads_df.iterrows():\n",
    "            p_s = put_spreads_df[put_spreads_df['put Combo'] == rowp['put Combo']]['Short Put Strike'].values[0]\n",
    "            p_l = put_spreads_df[put_spreads_df['put Combo'] == rowp['put Combo']]['Long Put Strike'].values[0]\n",
    "            c_s = call_spreads_df[call_spreads_df['call Combo'] == rowc['call Combo']]['Short call Strike'].values[0]\n",
    "            c_l = call_spreads_df[call_spreads_df['call Combo'] == rowc['call Combo']]['Long call Strike'].values[0]\n",
    "\n",
    "            put_short.append(p_s)\n",
    "            put_long.append(p_l)\n",
    "            call_short.append(c_s)\n",
    "            call_long.append(c_l)\n",
    "\n",
    "            curr_prem = rowp['put Spread Premium'] + rowc['call Spread Premium']\n",
    "\n",
    "            condor_prems.append(curr_prem)\n",
    "            condor_maxloss.append(100*(max(p_s - p_l, c_l - c_s) - curr_prem))\n",
    "            condor_delta.append(rowp['put Spread Delta'] + rowc['call Spread Delta'])\n",
    "            condor_gamma.append(rowp['put Spread Gamma'] + rowc['call Spread Gamma'])\n",
    "            condor_vega.append(rowp['put Spread Vega'] + rowc['call Spread Vega'])\n",
    "            condor_theta.append(rowp['put Spread Theta'] + rowc['call Spread Theta'])\n",
    "\n",
    "    condors_df = pd.DataFrame(OrderedDict({'P Short Strike': put_short,\n",
    "                                           'P Long Strike': put_long,\n",
    "                                           'C Short Strike': call_short,\n",
    "                                           'C Long Strike': call_long,\n",
    "                                           'Premium': condor_prems,\n",
    "                                           'Maxloss': condor_maxloss,\n",
    "                                           'Delta': condor_delta,\n",
    "                                           'Gamma': condor_gamma,\n",
    "                                           'Vega': condor_vega,\n",
    "                                           'Theta': condor_theta}),\n",
    "                                  index = range(len(condor_prems)))\n",
    "    condors_df['RiskRewardRatio'] = (100*condors_df['Premium'])/condors_df['Maxloss']\n",
    "    \n",
    "    return condors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 4335.747623920441 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "#active_stock_fundas = get_fundas(active_stocks[active_stocks['Last'] >= 30].index.tolist())\n",
    "#active_stock_fundas = active_stock_fundas[active_stock_fundas['Market Cap (B)'] >= 5]\n",
    "\n",
    "\n",
    "#tick_lst = active_stocks[active_stocks['Last'] >= 30].index.tolist()\n",
    "tick_lst = unusual_names.index.drop_duplicates().tolist()\n",
    "\n",
    "#etfs_lst = active_etfs[active_etfs['Last'] >= 50].index.tolist()\n",
    "\n",
    "\n",
    "days_since_earnings_threshold = 30\n",
    "mkt_cap_thresh = 5\n",
    "moneyness_thresh = 0.05\n",
    "hv_roll = 22\n",
    "dte_thresh = 30\n",
    "sort_on = 'intra_ann'\n",
    "max_options_num = 10 # Maximum number of names to look up\n",
    "iv_hv_thres = 0.9\n",
    "\n",
    "#etfs = current_volatility(etfs_lst, roll = 22).sort_values([sort_on], ascending = False).dropna()\n",
    "\n",
    "vols = current_volatility(tick_lst, roll = 22)\n",
    "vols = vols.sort_values([sort_on], ascending = False).dropna()\n",
    "fundas = get_fundas(vols.index.tolist())\n",
    "tickers = pd.concat([vols,fundas],axis = 1)\n",
    "tickers = tickers[(tickers['Days Since Last Earnings'] >= days_since_earnings_threshold)].sort_values([sort_on], \n",
    "                                                                                                      ascending = False)\n",
    "\n",
    "# etf_ticks = etfs.sort_values([sort_on], ascending = False)\n",
    "\n",
    "# pulled_options, pulled_calls, pulled_puts = phase1_options_filter(tickers.index.tolist()[:max_options_num], \n",
    "#                                                                   hv_roll, moneyness_thresh, dte_thresh,\n",
    "#                                                                   iv_hv_thres)\n",
    "\n",
    "# pulled_etfs, pulled_etfcalls, pulled_etfputs = phase1_options_filter(etf_ticks.index.tolist()[:max_options_num], \n",
    "#                                                                      hv_roll, moneyness_thresh, dte_thresh,\n",
    "#                                                                      iv_hv_thres)\n",
    "\n",
    "# filtered_single_names = (tickers.transpose()[pulled_options]).transpose()\n",
    "# filtered_single_names = (tickers.transpose()[pulled_options]).transpose()\n",
    "# filtered_single_names['IV'] = np.nan\n",
    "# for stock in pulled_options:\n",
    "#     filtered_single_names.loc[stock,'IV'] = pulled_puts[stock].sort_values(['Moneyness']).head(1).iloc[:, 0:-6].iloc[:,-1].iloc[0]\n",
    "    \n",
    "# filtered_etfs = (etf_ticks.transpose()[pulled_etfs]).transpose()\n",
    "# filtered_etfs = (etf_ticks.transpose()[pulled_etfs]).transpose()\n",
    "# filtered_etfs['IV'] = np.nan\n",
    "# for etf in pulled_etfs:\n",
    "#     filtered_etfs.loc[etf,'IV'] = pulled_etfputs[etf].sort_values(['Moneyness']).head(1).iloc[:, 0:-6].iloc[:,-1].iloc[0]\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>daily_ann</th>\n",
       "      <th>intra_ann</th>\n",
       "      <th>ovrnt_ann</th>\n",
       "      <th>daily_dollar_vol</th>\n",
       "      <th>Market Cap (B)</th>\n",
       "      <th>Price</th>\n",
       "      <th>Type</th>\n",
       "      <th>Strike</th>\n",
       "      <th>DTE</th>\n",
       "      <th>Bid</th>\n",
       "      <th>Midpoint</th>\n",
       "      <th>Ask</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open Interest</th>\n",
       "      <th>Vol/OI Ratio</th>\n",
       "      <th>IV</th>\n",
       "      <th>HV IV Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GE</th>\n",
       "      <td>0.388561</td>\n",
       "      <td>0.519205</td>\n",
       "      <td>0.240965</td>\n",
       "      <td>0.336070</td>\n",
       "      <td>118.17</td>\n",
       "      <td>13.24</td>\n",
       "      <td>Call</td>\n",
       "      <td>13.5</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1245.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.2790</td>\n",
       "      <td>0.240205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GE</th>\n",
       "      <td>0.388561</td>\n",
       "      <td>0.519205</td>\n",
       "      <td>0.240965</td>\n",
       "      <td>0.336070</td>\n",
       "      <td>118.17</td>\n",
       "      <td>13.24</td>\n",
       "      <td>Call</td>\n",
       "      <td>13.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.48</td>\n",
       "      <td>5128.0</td>\n",
       "      <td>4421.0</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0.2803</td>\n",
       "      <td>0.238905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GE</th>\n",
       "      <td>0.388561</td>\n",
       "      <td>0.519205</td>\n",
       "      <td>0.240965</td>\n",
       "      <td>0.336070</td>\n",
       "      <td>118.17</td>\n",
       "      <td>13.24</td>\n",
       "      <td>Put</td>\n",
       "      <td>13.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.29</td>\n",
       "      <td>652.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>3.40</td>\n",
       "      <td>0.2812</td>\n",
       "      <td>0.238005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GE</th>\n",
       "      <td>0.388561</td>\n",
       "      <td>0.519205</td>\n",
       "      <td>0.240965</td>\n",
       "      <td>0.336070</td>\n",
       "      <td>118.17</td>\n",
       "      <td>13.24</td>\n",
       "      <td>Call</td>\n",
       "      <td>13.5</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1130.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.2817</td>\n",
       "      <td>0.237505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GE</th>\n",
       "      <td>0.388561</td>\n",
       "      <td>0.519205</td>\n",
       "      <td>0.240965</td>\n",
       "      <td>0.336070</td>\n",
       "      <td>118.17</td>\n",
       "      <td>13.24</td>\n",
       "      <td>Call</td>\n",
       "      <td>13.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1749.0</td>\n",
       "      <td>977.0</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.2887</td>\n",
       "      <td>0.230505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GE</th>\n",
       "      <td>0.388561</td>\n",
       "      <td>0.519205</td>\n",
       "      <td>0.240965</td>\n",
       "      <td>0.336070</td>\n",
       "      <td>118.17</td>\n",
       "      <td>13.24</td>\n",
       "      <td>Put</td>\n",
       "      <td>13.5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1086.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.2983</td>\n",
       "      <td>0.220905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GE</th>\n",
       "      <td>0.388561</td>\n",
       "      <td>0.519205</td>\n",
       "      <td>0.240965</td>\n",
       "      <td>0.336070</td>\n",
       "      <td>118.17</td>\n",
       "      <td>13.24</td>\n",
       "      <td>Call</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3303.0</td>\n",
       "      <td>3080.0</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.3013</td>\n",
       "      <td>0.217905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GE</th>\n",
       "      <td>0.388561</td>\n",
       "      <td>0.519205</td>\n",
       "      <td>0.240965</td>\n",
       "      <td>0.336070</td>\n",
       "      <td>118.17</td>\n",
       "      <td>13.24</td>\n",
       "      <td>Put</td>\n",
       "      <td>12.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1623.0</td>\n",
       "      <td>1081.0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.3028</td>\n",
       "      <td>0.216405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GE</th>\n",
       "      <td>0.388561</td>\n",
       "      <td>0.519205</td>\n",
       "      <td>0.240965</td>\n",
       "      <td>0.336070</td>\n",
       "      <td>118.17</td>\n",
       "      <td>13.24</td>\n",
       "      <td>Put</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3448.0</td>\n",
       "      <td>1153.0</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.3053</td>\n",
       "      <td>0.213905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GE</th>\n",
       "      <td>0.388561</td>\n",
       "      <td>0.519205</td>\n",
       "      <td>0.240965</td>\n",
       "      <td>0.336070</td>\n",
       "      <td>118.17</td>\n",
       "      <td>13.24</td>\n",
       "      <td>Call</td>\n",
       "      <td>13.5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>10529.0</td>\n",
       "      <td>2615.0</td>\n",
       "      <td>4.03</td>\n",
       "      <td>0.3159</td>\n",
       "      <td>0.203305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSCO</th>\n",
       "      <td>0.217421</td>\n",
       "      <td>0.368193</td>\n",
       "      <td>0.116484</td>\n",
       "      <td>0.580721</td>\n",
       "      <td>207.30</td>\n",
       "      <td>41.95</td>\n",
       "      <td>Call</td>\n",
       "      <td>42.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1259.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>5.29</td>\n",
       "      <td>0.1869</td>\n",
       "      <td>0.181293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>0.145283</td>\n",
       "      <td>0.299675</td>\n",
       "      <td>0.075521</td>\n",
       "      <td>1.026212</td>\n",
       "      <td>155.83</td>\n",
       "      <td>111.44</td>\n",
       "      <td>Call</td>\n",
       "      <td>135.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.07</td>\n",
       "      <td>923.0</td>\n",
       "      <td>632.0</td>\n",
       "      <td>1.46</td>\n",
       "      <td>0.2077</td>\n",
       "      <td>0.091975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      daily_ann  intra_ann  ovrnt_ann  daily_dollar_vol  Market Cap (B)  \\\n",
       "GE     0.388561   0.519205   0.240965          0.336070          118.17   \n",
       "GE     0.388561   0.519205   0.240965          0.336070          118.17   \n",
       "GE     0.388561   0.519205   0.240965          0.336070          118.17   \n",
       "GE     0.388561   0.519205   0.240965          0.336070          118.17   \n",
       "GE     0.388561   0.519205   0.240965          0.336070          118.17   \n",
       "GE     0.388561   0.519205   0.240965          0.336070          118.17   \n",
       "GE     0.388561   0.519205   0.240965          0.336070          118.17   \n",
       "GE     0.388561   0.519205   0.240965          0.336070          118.17   \n",
       "GE     0.388561   0.519205   0.240965          0.336070          118.17   \n",
       "GE     0.388561   0.519205   0.240965          0.336070          118.17   \n",
       "CSCO   0.217421   0.368193   0.116484          0.580721          207.30   \n",
       "DIS    0.145283   0.299675   0.075521          1.026212          155.83   \n",
       "\n",
       "       Price  Type  Strike   DTE   Bid  Midpoint   Ask   Volume  \\\n",
       "GE     13.24  Call    13.5  41.0  0.33      0.34  0.35   1245.0   \n",
       "GE     13.24  Call    13.0  27.0  0.46      0.47  0.48   5128.0   \n",
       "GE     13.24   Put    13.0  20.0  0.27      0.28  0.29    652.0   \n",
       "GE     13.24  Call    13.5  34.0  0.29      0.30  0.31   1130.0   \n",
       "GE     13.24  Call    13.5  20.0  0.20      0.21  0.21   1749.0   \n",
       "GE     13.24   Put    13.5  13.0  0.51      0.52  0.53   1086.0   \n",
       "GE     13.24  Call    14.0  20.0  0.09      0.10  0.10   3303.0   \n",
       "GE     13.24   Put    12.5  20.0  0.12      0.13  0.14   1623.0   \n",
       "GE     13.24   Put    13.0  13.0  0.23      0.24  0.25   3448.0   \n",
       "GE     13.24  Call    13.5  13.0  0.16      0.17  0.17  10529.0   \n",
       "CSCO   41.95  Call    42.0  13.0  0.57      0.58  0.59   1259.0   \n",
       "DIS   111.44  Call   135.0  62.0  0.05      0.06  0.07    923.0   \n",
       "\n",
       "      Open Interest  Vol/OI Ratio      IV  HV IV Diff  \n",
       "GE            518.0          2.40  0.2790    0.240205  \n",
       "GE           4421.0          1.16  0.2803    0.238905  \n",
       "GE            192.0          3.40  0.2812    0.238005  \n",
       "GE           1014.0          1.11  0.2817    0.237505  \n",
       "GE            977.0          1.79  0.2887    0.230505  \n",
       "GE           1017.0          1.07  0.2983    0.220905  \n",
       "GE           3080.0          1.07  0.3013    0.217905  \n",
       "GE           1081.0          1.50  0.3028    0.216405  \n",
       "GE           1153.0          2.99  0.3053    0.213905  \n",
       "GE           2615.0          4.03  0.3159    0.203305  \n",
       "CSCO          238.0          5.29  0.1869    0.181293  \n",
       "DIS           632.0          1.46  0.2077    0.091975  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unusual_scan = tickers[['daily_ann','intra_ann',\n",
    "                        'ovrnt_ann','daily_dollar_vol',\n",
    "                        'Market Cap (B)']].join(unusual_names[['Price','Type','Strike','DTE',\n",
    "                                                               'Bid','Midpoint','Ask','Volume',\n",
    "                                                               'Open Interest','Vol/OI Ratio', \n",
    "                                                               'IV']], how = 'right').dropna()\n",
    "unusual_scan['HV IV Diff'] = unusual_scan['intra_ann'] - unusual_scan['IV']\n",
    "unusual_scan[(unusual_scan['Market Cap (B)'] <= 500) &\n",
    "             (unusual_scan['Market Cap (B)'] >= 0) &\n",
    "             (unusual_scan['Midpoint'] - unusual_scan['Bid'] <= 0.02) &\n",
    "             (unusual_scan['DTE'] >= 10) &\n",
    "             (unusual_scan['intra_ann'] > unusual_scan['IV'])].sort_values(['IV'], \n",
    "                                                                           ascending = False).sort_values('HV IV Diff',\n",
    "                                                                                                         ascending = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2.458791494369507 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# back_ratio_opt(ticker_lst, max_rows, short_pos, long_pos, order_style, theta_thresh, delta_thresh,\n",
    "#                    dte_lb, dte_ub\n",
    "\n",
    "# combos = back_ratio_opt(unusual_scan.index.drop_duplicates().tolist(),\n",
    "#                         10, 1, 2, 'market', 0, 0.05, 30, 210)\n",
    "combos = back_ratio_opt(['UVXY'],\n",
    "                         10, 1, 2, 'market', 0, 0.05, 30, 210)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Delta</th>\n",
       "      <th>Gamma</th>\n",
       "      <th>Long Ask</th>\n",
       "      <th>Long Bid</th>\n",
       "      <th>Long Strike</th>\n",
       "      <th>Max Loss</th>\n",
       "      <th>Net Credit</th>\n",
       "      <th>Short Ask</th>\n",
       "      <th>Short Bid</th>\n",
       "      <th>Short Strike</th>\n",
       "      <th>Theta</th>\n",
       "      <th>Vega</th>\n",
       "      <th>DTE</th>\n",
       "      <th>Type</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.034214</td>\n",
       "      <td>-0.008401</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.14</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.001225</td>\n",
       "      <td>-0.001463</td>\n",
       "      <td>64</td>\n",
       "      <td>put</td>\n",
       "      <td>UVXY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Delta     Gamma  Long Ask  Long Bid  Long Strike  Max Loss  Net Credit  \\\n",
       "0  0.034214 -0.008401      0.06      0.02          5.0     -0.98        0.02   \n",
       "\n",
       "   Short Ask  Short Bid  Short Strike     Theta      Vega  DTE Type Ticker  \n",
       "0        0.2       0.14           6.0  0.001225 -0.001463   64  put   UVXY  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combos[(combos['Long Ask'] != 0) &\n",
    "#        (abs(combos['Long Strike'] - combos['Short Strike']) <= 5) &\n",
    "#        (abs(combos['Delta']) <= 0.02)]\n",
    "\n",
    "combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
