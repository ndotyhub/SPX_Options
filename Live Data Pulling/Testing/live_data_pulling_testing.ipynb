{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing necessary models\n",
    "import smtplib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import pandas.stats.moments as st\n",
    "from pandas import ExcelWriter\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as dates\n",
    "import matplotlib.ticker as ticker\n",
    "from lxml import html\n",
    "import requests\n",
    "import webbrowser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "import glob\n",
    "from time import sleep\n",
    "import sched, time\n",
    "from pandas_datareader.data import Options\n",
    "from py_vollib.black_scholes_merton.implied_volatility import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulling Yahoo live data\n",
    "\n",
    "'''\n",
    "Function for pulling latest SPX, VIX, VVIX, or SKEW data. Input is a string, pulls \n",
    "the latest 2 lines of data from yahoo finance for given ticker and returns a \n",
    "dataframe of the open and close with the latest date as the first row.\n",
    "'''\n",
    "def latest_yahoo(ticker = 'SPX'):\n",
    "    # Using requests to ping yahoo finance to retrieve \n",
    "    # historical data table\n",
    "    if ticker == 'VIX':\n",
    "        site = 'https://finance.yahoo.com/quote/%5EVIX/history?p=^VIX'\n",
    "    elif ticker == 'VVIX':\n",
    "        site = 'https://finance.yahoo.com/quote/%5EVVIX/history?p=^VVIX'\n",
    "    elif ticker == 'SKEW':\n",
    "        site = 'https://finance.yahoo.com/quote/%5ESKEW/history?p=^SKEW'\n",
    "    else:\n",
    "        site = 'https://finance.yahoo.com/quote/%5EGSPC/history?p=^GSPC'\n",
    "        \n",
    "    res = requests.get(site)\n",
    "    soup = bs(res.text, 'lxml')\n",
    "    table = soup.find_all('table')[0]\n",
    "\n",
    "    # Initializing list to store date, open, and close values\n",
    "    # for GSPC\n",
    "    dates = []\n",
    "    opens = []\n",
    "    closes = []\n",
    "    \n",
    "    # Looping through the soup lxml text table format\n",
    "    # and splitting each row as a individual string\n",
    "    # and parsing string to retrieve the date,\n",
    "    # open, and close information.\n",
    "    i = 1\n",
    "    end_row = 3\n",
    "    for row in table.find_all('tr'):\n",
    "        # Individual row stores current row item and delimits on '\\n'\n",
    "        individual_row = str(row).split('\\n')\n",
    "        \n",
    "        # row_items is parsed string for each current row where each\n",
    "        # item in list is the date, open, high, low, close, and volume\n",
    "        row_items = [item.split('>')[1] for item in [string.split('</span>')[0] for string in individual_row[0].split('<span ')[1:]]]\n",
    "        \n",
    "        if i == 1:\n",
    "            # Skip first row because they are column headers\n",
    "            i += 1\n",
    "            continue\n",
    "        elif i == end_row:\n",
    "            break\n",
    "        else:\n",
    "            # Append necessary items to initialized lists for \n",
    "            # dataframe storage\n",
    "            dates.append(dt.datetime.strptime(row_items[0], '%b %d, %Y'))\n",
    "            opens.append(float(row_items[1].replace(',','')))\n",
    "            closes.append(float(row_items[5].replace(',','')))\n",
    "        i += 1\n",
    "    \n",
    "    # Return dataframe of necessary values\n",
    "    return pd.DataFrame({ticker + ' Open': opens,ticker + ' Close': closes}, index = dates)\n",
    "    \n",
    "'''\n",
    "Function for pulling options data from yahoo Input is a string, either 'call' or 'put' to\n",
    "determine the contract type to pull from yahoo finance. The output is a dataframe of the latest\n",
    "data from yahoo finance tagged with the current date-time. Output columns are pull date-time,\n",
    "contract name, strike, last price, bid, ask volume, open interest, and IV (in decimal form).\n",
    "'''\n",
    "def yahoo_options(contract = 'put'):\n",
    "    # Using request to ping yahoo and retrieve the raw html\n",
    "    # tables for calls and puts data for gspc\n",
    "    site = 'https://finance.yahoo.com/quote/%5EGSPC/options?p=%5EGSPC'\n",
    "    res = requests.get(site)\n",
    "    soup = bs(res.text, 'lxml')\n",
    "    calls = soup.find_all('table')[0]\n",
    "    puts = soup.find_all('table')[1]\n",
    "    if contract == 'call':\n",
    "        table = calls\n",
    "    else:\n",
    "        table = puts\n",
    "        \n",
    "    # parsing calls table\n",
    "    \n",
    "    # initiating data lists for storing column data\n",
    "    dates = []\n",
    "    names = []\n",
    "    strikes = []\n",
    "    lprices = []\n",
    "    bids = []\n",
    "    asks = []\n",
    "    volumes = []\n",
    "    open_interests = []\n",
    "    iv = []\n",
    "    current_time = dt.datetime.now()\n",
    "    \n",
    "    # starting with counter i so that the first row in the\n",
    "    # specified table is noted as the header row\n",
    "    i = 1\n",
    "    for row in table.find_all('tr'):\n",
    "        rowstring = str(row).split('\\n')\n",
    "        # if first row, store data as header labels for dataframe use\n",
    "        if i == 1:\n",
    "            header = [data.split('>')[1] for data in \\\n",
    "                        [rawstring.split('</span>')[0] for \\\n",
    "                         rawstring in rowstring[0].split('<span')[1:]]]\n",
    "        else:\n",
    "        # parsing other raw row strings to retrieve necessary data and append them\n",
    "        # to their corresponding list.\n",
    "            row_data = rowstring[0].split('data-reactid=')[3:]\n",
    "            dates.append(current_time)\n",
    "            names.append(row_data[0].split('title=\"')[1].split('\"')[0])\n",
    "            strikes.append(float(row_data[3].split('</a>')[0].split('>')[1].replace(',','')))\n",
    "            lprices.append(float(row_data[4].split('</td>')[0].split('>')[1].replace(',','')))\n",
    "            bids.append(float(row_data[5].split('</td>')[0].split('>')[1].replace(',','')))\n",
    "            asks.append(float(row_data[6].split('</td>')[0].split('>')[1].replace(',','')))\n",
    "            volumes.append(float(row_data[-3].split('</td>')[0].split('>')[1].replace(',','')))\n",
    "            open_interests.append(float(row_data[-2].split('</td>')[0].split('>')[1].replace(',','')))\n",
    "            iv.append(float(row_data[-1].split('</td>')[0].split('>')[1].replace(',','').replace('%',''))/100)\n",
    "        i += 1\n",
    "\n",
    "    return pd.DataFrame({'Pull Date': dates,\n",
    "                          contract + ' ' + header[0]: names,\n",
    "                          header[2]: strikes,\n",
    "                          header[3]: lprices,\n",
    "                          header[4]: bids,\n",
    "                          header[5]: asks,\n",
    "                          header[-3]: volumes,\n",
    "                          header[-2]: open_interests,\n",
    "                          header[-1]: iv})\n",
    "'''\n",
    "Similar to above, the yahoo_historical function scrapes data from yahoo finance. This time\n",
    "it scrapes all historical data from yahoo finance and stores in a data frame. Only used for\n",
    "VVIX and SPX index\n",
    "'''\n",
    "\n",
    "# Use six to import urllib so it is working for Python2/3\n",
    "from six.moves import urllib\n",
    "# If you don't want to use six, please comment out the line above\n",
    "# and use the line below instead (for Python3 only).\n",
    "#import urllib.request, urllib.parse, urllib.error\n",
    "\n",
    "import time\n",
    "\n",
    "'''\n",
    "Starting on May 2017, Yahoo financial has terminated its service on\n",
    "the well used EOD data download without warning. This is confirmed\n",
    "by Yahoo employee in forum posts.\n",
    "Yahoo financial EOD data, however, still works on Yahoo financial pages.\n",
    "These download links uses a \"crumb\" for authentication with a cookie \"B\".\n",
    "This code is provided to obtain such matching cookie and crumb.\n",
    "'''\n",
    "\n",
    "# Build the cookie handler\n",
    "cookier = urllib.request.HTTPCookieProcessor()\n",
    "opener = urllib.request.build_opener(cookier)\n",
    "urllib.request.install_opener(opener)\n",
    "\n",
    "# Cookie and corresponding crumb\n",
    "_cookie = None\n",
    "_crumb = None\n",
    "\n",
    "_headers={'User-Agent': 'Mozilla/5.0 (X11; U; Linux i686) Gecko/20071127 Firefox/2.0.0.11'}\n",
    "\n",
    "def get_cookie_crumb():\n",
    "    '''\n",
    "    This function perform a query and extract the matching cookie and crumb.\n",
    "    '''\n",
    "\n",
    "    # Perform a Yahoo financial lookup on SP500\n",
    "    req = urllib.request.Request('https://finance.yahoo.com/quote/^GSPC', headers=_headers)\n",
    "    f = urllib.request.urlopen(req)\n",
    "    alines = f.read().decode('utf-8')\n",
    "\n",
    "    # Extract the crumb from the response\n",
    "    global _crumb\n",
    "    cs = alines.find('CrumbStore')\n",
    "    cr = alines.find('crumb', cs + 10)\n",
    "    cl = alines.find(':', cr + 5)\n",
    "    q1 = alines.find('\"', cl + 1)\n",
    "    q2 = alines.find('\"', q1 + 1)\n",
    "    crumb = alines[q1 + 1:q2]\n",
    "    _crumb = crumb\n",
    "\n",
    "    # Extract the cookie from cookiejar\n",
    "    global cookier, _cookie\n",
    "    for c in cookier.cookiejar:\n",
    "        if c.domain != '.yahoo.com':\n",
    "            continue\n",
    "        if c.name != 'B':\n",
    "            continue\n",
    "    _cookie = c.value\n",
    "\n",
    "    # Print the cookie and crumb\n",
    "    # print('Cookie:', _cookie)\n",
    "    # print('Crumb:', _crumb)\n",
    "    return _crumb\n",
    "\n",
    "\n",
    "def yahoo_historical(ticker = 'SPX'):\n",
    "    # Using requests to ping yahoo finance to retrieve \n",
    "    # historical data table\n",
    "    \n",
    "    # Getting cookie crumb for yahoo finance query\n",
    "    get_cookie_crumb()\n",
    "    \n",
    "    if ticker == 'VVIX':\n",
    "        site = 'https://query1.finance.yahoo.com/v7/finance/download/%5EVVIX?period1=1167811200&period2=' + str(int(time.time())) + '&interval=1d&events=history&crumb=' + get_cookie_crumb().replace('\\\\','')\n",
    "    else:\n",
    "        site = 'https://query1.finance.yahoo.com/v7/finance/download/%5EGSPC?period1=-630950400&period2=' + str(int(time.time())) + '&interval=1d&events=history&crumb=' + get_cookie_crumb().replace('\\\\','')\n",
    "    \n",
    "    df = pd.read_csv(site)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx = yahoo_historical()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
